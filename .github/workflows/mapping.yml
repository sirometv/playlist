name: Mapping

on:
  schedule:
    - cron: '*/5 * * * *'
  workflow_dispatch:

permissions:
  contents: write

jobs:
  sync-channels:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
        
    - name: Download playlists
      run: |
        echo "üì• Downloading playlists..."
        curl -s -L -o main_playlist.m3u "https://raw.githubusercontent.com/sirometv/playlist/main/sirometv.m3u"
        curl -s -L -o source_playlist.m3u "https://raw.githubusercontent.com/sirometv/playlist/main/Ayna.m3u"
        
        for file in main_playlist.m3u source_playlist.m3u; do
          if [ ! -f "$file" ] || [ ! -s "$file" ]; then
            echo "‚ùå ERROR: $file download failed!"
            exit 1
          fi
          LINES=$(wc -l < "$file")
          echo "‚úÖ $file downloaded - $LINES lines"
        done
        
    - name: Update All Channel
      run: |
        echo "üîÑ Updating All Channel..."
        
        python3 - << 'EOF'
        import re
        from datetime import datetime
        import pytz
        
        # ‡¶ö‡ßç‡¶Ø‡¶æ‡¶®‡ßá‡¶≤ ‡¶Æ‡ßç‡¶Ø‡¶æ‡¶™‡¶ø‡¶Ç - ‡¶Æ‡ßá‡¶á‡¶® ‡¶ö‡ßç‡¶Ø‡¶æ‡¶®‡ßá‡¶≤‡ßá‡¶∞ ‡¶®‡¶æ‡¶Æ : [‡¶∏‡ßã‡¶∞‡ßç‡¶∏ ‡¶ö‡ßç‡¶Ø‡¶æ‡¶®‡ßá‡¶≤‡ßá‡¶∞ exact keywords]
        CHANNEL_MAPPING = {
            "T Sports": ["T Sports HD", "A Sports", "PTV Sports"],
            "BTV National": ["BTV NATIONAL HD", "BTV World"],
            "BTV CTG": ["BTV CTG"],
            "Channel 9": ["Channel 9"],
            "Channel I": ["Channel I"],
            "Bangla Vision": ["Bangla Vision"],
            "News 24": ["News 24 BD"], 
            "Boishakhi TV": ["Boishakhi TV"],
            "Bijoy TV": ["Bijoy TV"],
            "ATN Bangla": ["ATN Bangla"],
            "ATN-Bangla News": ["ATN News"],
            "DBC News": ["DBC News"],
            "Independent TV": ["Independent TV"],
            "Bangla TV": ["Bangla TV"],
            "Desh TV": ["Desh TV"],
            "RTV": ["RTV"],
            "My TV": ["My TV"],
            # "Somoy TV": ["Somoy News TV", "Somoy TV"],
            # ‡¶è‡¶ñ‡¶æ‡¶®‡ßá ‡¶Ü‡¶™‡¶®‡¶ø ‡¶Ü‡¶∞‡ßã ‡¶ö‡ßç‡¶Ø‡¶æ‡¶®‡ßá‡¶≤ ‡¶Ø‡ßã‡¶ó ‡¶ï‡¶∞‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡¶¨‡ßá‡¶®
            # "Channel Name in Main": ["exact_keyword1", "exact_keyword2", "exact_keyword3"]
        }
        
        def get_bangladesh_time():
            """‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ‡¶¶‡ßá‡¶∂‡ßá‡¶∞ ‡¶¨‡¶∞‡ßç‡¶§‡¶Æ‡¶æ‡¶® ‡¶∏‡¶Æ‡¶Ø‡¶º ‡¶∞‡¶ø‡¶ü‡¶æ‡¶∞‡ßç‡¶® ‡¶ï‡¶∞‡ßá"""
            bangladesh_tz = pytz.timezone('Asia/Dhaka')
            now = datetime.now(bangladesh_tz)
            return now.strftime("%Y-%m-%d %I:%M:%S%p BD Time") + " üîÑ"
        
        def find_channel_urls(source_file, keywords):
            """‡¶∏‡ßã‡¶∞‡ßç‡¶∏ ‡¶™‡ßç‡¶≤‡ßá‡¶≤‡¶ø‡¶∏‡ßç‡¶ü ‡¶•‡ßá‡¶ï‡ßá ‡¶è‡¶ï‡¶æ‡¶ß‡¶ø‡¶ï ‡¶ö‡ßç‡¶Ø‡¶æ‡¶®‡ßá‡¶≤‡ßá‡¶∞ URL ‡¶ñ‡ßÅ‡¶Å‡¶ú‡ßá ‡¶¨‡ßá‡¶∞ ‡¶ï‡¶∞‡ßá"""
            with open(source_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
            urls = []
            
            # ‡¶∏‡ßã‡¶∞‡ßç‡¶∏ ‡¶™‡ßç‡¶≤‡ßá‡¶≤‡¶ø‡¶∏‡ßç‡¶ü‡¶ï‡ßá ‡¶≤‡¶æ‡¶á‡¶®‡ßá ‡¶≠‡¶æ‡¶ó ‡¶ï‡¶∞‡ßÅ‡¶®
            lines = content.split('\n')
            i = 0
            
            while i < len(lines):
                line = lines[i]
                # EXTINF ‡¶≤‡¶æ‡¶á‡¶® ‡¶ñ‡ßÅ‡¶Å‡¶ú‡ßÅ‡¶®
                if line.startswith('#EXTINF:'):
                    extinf_line = line
                    channel_name_part = extinf_line.split(',', 1)[1] if ',' in extinf_line else ""
                    
                    # ‡¶™‡¶∞‡ßá‡¶∞ ‡¶≤‡¶æ‡¶á‡¶® URL ‡¶π‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡ßá
                    if i + 1 < len(lines) and lines[i + 1].startswith('http'):
                        url_line = lines[i + 1]
                        
                        # ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶ü‡¶ø keyword ‡¶è‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶ö‡ßá‡¶ï ‡¶ï‡¶∞‡ßÅ‡¶®
                        for keyword in keywords:
                            # Exact match ‡¶ö‡ßá‡¶ï - keyword ‡¶ö‡ßç‡¶Ø‡¶æ‡¶®‡ßá‡¶≤ ‡¶®‡¶æ‡¶Æ‡ßá‡¶∞ ‡¶Æ‡¶ß‡ßç‡¶Ø‡ßá exact match ‡¶π‡¶§‡ßá ‡¶π‡¶¨‡ßá
                            # Case insensitive match
                            pattern = r'\b' + re.escape(keyword) + r'\b'
                            if re.search(pattern, channel_name_part, re.IGNORECASE):
                                print(f"‚úÖ Exact match found: '{keyword}' in '{channel_name_part}'")
                                urls.append((keyword, url_line.strip()))
                                break  # ‡¶è‡¶ï‡¶¨‡¶æ‡¶∞ ‡¶Æ‡ßç‡¶Ø‡¶æ‡¶ö ‡¶™‡ßá‡¶≤‡ßá ‡¶™‡¶∞‡ßá‡¶∞ keyword ‡¶ö‡ßá‡¶ï ‡¶ï‡¶∞‡¶æ‡¶∞ ‡¶¶‡¶∞‡¶ï‡¶æ‡¶∞ ‡¶®‡ßá‡¶á
                        i += 2  # EXTINF ‡¶è‡¶¨‡¶Ç URL ‡¶≤‡¶æ‡¶á‡¶® ‡¶∏‡ßç‡¶ï‡¶ø‡¶™ ‡¶ï‡¶∞‡ßÅ‡¶®
                    else:
                        i += 1
                else:
                    i += 1
            
            # ‡¶Ø‡¶¶‡¶ø ‡¶ï‡ßã‡¶®‡ßã URL ‡¶®‡¶æ ‡¶™‡¶æ‡¶ì‡ßü‡¶æ ‡¶Ø‡¶æ‡ßü, ‡¶§‡¶æ‡¶π‡¶≤‡ßá backup method ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡ßÅ‡¶®
            if not urls:
                for keyword in keywords:
                    # Backup regex method
                    pattern = rf'#EXTINF:-1[^,]*,[^,]*\b{re.escape(keyword)}\b[^\n]*\n(http[^\n]+)'
                    match = re.search(pattern, content, re.IGNORECASE)
                    if match:
                        url = match.group(1).strip()
                        print(f"‚úÖ Backup method found: '{keyword}' -> {url[:80]}...")
                        urls.append((keyword, url))
            
            if urls:
                print(f"‚úÖ Total URLs found: {len(urls)}")
            else:
                print(f"‚ùå No URLs found for keywords: {keywords}")
            
            return urls
        
        def process_channel_with_auto_updated(lines, start_idx, channel_name, new_urls, is_manual_run):
            """‡¶è‡¶ï‡¶ü‡¶ø ‡¶ö‡ßç‡¶Ø‡¶æ‡¶®‡ßá‡¶≤ ‡¶™‡ßç‡¶∞‡¶∏‡ßá‡¶∏ ‡¶ï‡¶∞‡ßá AUTO-UPDATED ‡¶∏‡ßá‡¶ï‡¶∂‡¶® ‡¶Ø‡ßã‡¶ó/‡¶Ü‡¶™‡¶°‡ßá‡¶ü ‡¶ï‡¶∞‡ßá"""
            # ‡¶ö‡ßç‡¶Ø‡¶æ‡¶®‡ßá‡¶≤‡ßá‡¶∞ ‡¶∂‡ßá‡¶∑ ‡¶ñ‡ßÅ‡¶Å‡¶ú‡ßá ‡¶¨‡ßá‡¶∞ ‡¶ï‡¶∞‡ßÅ‡¶® (‡¶™‡¶∞‡¶¨‡¶∞‡ßç‡¶§‡ßÄ EXTINF ‡¶¨‡¶æ ‡¶´‡¶æ‡¶á‡¶≤ ‡¶∂‡ßá‡¶∑)
            end_idx = start_idx
            for i in range(start_idx + 1, len(lines)):
                if lines[i].startswith('#EXTINF:'):
                    end_idx = i - 1
                    break
                if i == len(lines) - 1:
                    end_idx = i
                    break
            
            print(f"   Channel block: lines {start_idx+1} to {end_idx+1}")
            
            # ‡¶®‡¶§‡ßÅ‡¶® ‡¶≤‡¶æ‡¶á‡¶® ‡¶§‡ßà‡¶∞‡¶ø ‡¶ï‡¶∞‡¶ø
            new_block_lines = []
            
            # EXTINF ‡¶≤‡¶æ‡¶á‡¶® ‡¶Ø‡ßã‡¶ó ‡¶ï‡¶∞‡¶ø
            new_block_lines.append(lines[start_idx])
            
            # ‡¶è‡¶ñ‡¶® AUTO-UPDATED ‡¶∏‡ßá‡¶ï‡¶∂‡¶® ‡¶ñ‡ßÅ‡¶Å‡¶ú‡¶ø
            auto_updated_start = -1
            auto_updated_end = -1
            
            for i in range(start_idx + 1, end_idx + 1):
                if lines[i].startswith('#AUTO-UPDATED'):
                    auto_updated_start = i
                    # AUTO-UPDATED ‡¶∏‡ßá‡¶ï‡¶∂‡¶®‡ßá‡¶∞ ‡¶∂‡ßá‡¶∑ ‡¶ñ‡ßÅ‡¶Å‡¶ú‡¶ø
                    for j in range(i + 1, end_idx + 1):
                        if not (lines[j].startswith('http://') or lines[j].startswith('https://')):
                            auto_updated_end = j - 1
                            break
                    if auto_updated_end == -1:
                        auto_updated_end = end_idx
                    break
            
            timestamp = get_bangladesh_time()
            refresh_emoji = "üîÑ" * len(new_urls) if new_urls else ""
            timestamp_with_emoji = f"{timestamp.split(' üîÑ')[0]} {refresh_emoji}"
            
            # ‡¶®‡¶§‡ßÅ‡¶® AUTO-UPDATED ‡¶∏‡ßá‡¶ï‡¶∂‡¶® ‡¶§‡ßà‡¶∞‡¶ø ‡¶ï‡¶∞‡¶ø
            new_auto_section = f"#AUTO-UPDATED - {channel_name} - {timestamp_with_emoji}\n"
            for keyword, url in new_urls:
                new_auto_section += f"{url}\n"
            
            if auto_updated_start != -1:
                print(f"   Found existing AUTO-UPDATED at line {auto_updated_start+1}")
                # AUTO-UPDATED ‡¶∏‡ßá‡¶ï‡¶∂‡¶® replace ‡¶ï‡¶∞‡¶ø
                # ‡¶™‡ßç‡¶∞‡¶•‡¶Æ‡ßá EXTINF ‡¶≤‡¶æ‡¶á‡¶®‡ßá‡¶∞ ‡¶™‡¶∞ ‡¶•‡ßá‡¶ï‡ßá auto_updated_start ‡¶è‡¶∞ ‡¶Ü‡¶ó ‡¶™‡¶∞‡ßç‡¶Ø‡¶®‡ßç‡¶§ ‡¶∏‡¶¨ ‡¶≤‡¶æ‡¶á‡¶® ‡¶Ø‡ßã‡¶ó ‡¶ï‡¶∞‡¶ø
                for i in range(start_idx + 1, auto_updated_start):
                    new_block_lines.append(lines[i])
                
                # ‡¶®‡¶§‡ßÅ‡¶® AUTO-UPDATED ‡¶∏‡ßá‡¶ï‡¶∂‡¶® ‡¶Ø‡ßã‡¶ó ‡¶ï‡¶∞‡¶ø
                new_block_lines.extend(new_auto_section.strip().split('\n'))
                
                # auto_updated_end ‡¶è‡¶∞ ‡¶™‡¶∞ ‡¶•‡ßá‡¶ï‡ßá end_idx ‡¶™‡¶∞‡ßç‡¶Ø‡¶®‡ßç‡¶§ ‡¶∏‡¶¨ ‡¶≤‡¶æ‡¶á‡¶® ‡¶Ø‡ßã‡¶ó ‡¶ï‡¶∞‡¶ø
                for i in range(auto_updated_end + 1, end_idx + 1):
                    new_block_lines.append(lines[i])
                
                print(f"   Replaced AUTO-UPDATED section")
            else:
                print(f"   No AUTO-UPDATED section found, adding new one")
                # EXTINF ‡¶≤‡¶æ‡¶á‡¶®‡ßá‡¶∞ ‡¶™‡¶∞‡ßá‡¶á ‡¶®‡¶§‡ßÅ‡¶® AUTO-UPDATED ‡¶∏‡ßá‡¶ï‡¶∂‡¶® ‡¶Ø‡ßã‡¶ó ‡¶ï‡¶∞‡¶ø
                # ‡¶§‡¶æ‡¶∞‡¶™‡¶∞ ‡¶¨‡¶æ‡¶ï‡¶ø ‡¶∏‡¶¨ ‡¶≤‡¶æ‡¶á‡¶® ‡¶Ø‡ßã‡¶ó ‡¶ï‡¶∞‡¶ø
                new_block_lines.extend(new_auto_section.strip().split('\n'))
                
                # EXTINF ‡¶≤‡¶æ‡¶á‡¶®‡ßá‡¶∞ ‡¶™‡¶∞‡ßá‡¶∞ ‡¶∏‡¶¨ ‡¶≤‡¶æ‡¶á‡¶® ‡¶Ø‡ßã‡¶ó ‡¶ï‡¶∞‡¶ø
                for i in range(start_idx + 1, end_idx + 1):
                    new_block_lines.append(lines[i])
                
                print(f"   Added new AUTO-UPDATED section")
            
            return new_block_lines, end_idx
        
        # ‡¶Æ‡ßá‡¶á‡¶® ‡¶™‡ßç‡¶≤‡ßá‡¶≤‡¶ø‡¶∏‡ßç‡¶ü ‡¶≤‡ßã‡¶° ‡¶ï‡¶∞‡ßÅ‡¶®
        with open('main_playlist.m3u', 'r', encoding='utf-8') as f:
            main_content = f.read()
        
        # Check if manual run or scheduled
        import os
        is_manual_run = os.environ.get('GITHUB_EVENT_NAME') == 'workflow_dispatch'
        
        print(f"üìä Run type: {'Manual' if is_manual_run else 'Scheduled'}")
        print(f"üìä Total channels in mapping: {len(CHANNEL_MAPPING)}")
        
        # ‡¶≤‡¶æ‡¶á‡¶® ‡¶¨‡¶æ‡¶á ‡¶≤‡¶æ‡¶á‡¶® ‡¶™‡ßç‡¶∞‡¶∏‡ßá‡¶∏ ‡¶ï‡¶∞‡¶ø
        lines = main_content.split('\n')
        new_lines = []
        i = 0
        channels_updated = 0
        
        while i < len(lines):
            line = lines[i]
            
            # ‡¶Ø‡¶¶‡¶ø EXTINF ‡¶≤‡¶æ‡¶á‡¶® ‡¶π‡ßü
            if line.startswith('#EXTINF:'):
                # ‡¶ï‡ßã‡¶® ‡¶ö‡ßç‡¶Ø‡¶æ‡¶®‡ßá‡¶≤‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶ö‡ßá‡¶ï ‡¶ï‡¶∞‡¶õ‡¶ø
                current_channel = None
                for channel_name in CHANNEL_MAPPING.keys():
                    if channel_name in line:
                        current_channel = channel_name
                        break
                
                if current_channel:
                    print(f"\n{'='*50}")
                    print(f"üîç Processing mapped channel: {current_channel} at line {i+1}")
                    
                    # ‡¶è‡¶á ‡¶ö‡ßç‡¶Ø‡¶æ‡¶®‡ßá‡¶≤‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø URL ‡¶ñ‡ßÅ‡¶Å‡¶ú‡¶ø
                    new_urls = find_channel_urls('source_playlist.m3u', CHANNEL_MAPPING[current_channel])
                    
                    if new_urls:
                        # ‡¶ö‡ßç‡¶Ø‡¶æ‡¶®‡ßá‡¶≤ ‡¶™‡ßç‡¶∞‡¶∏‡ßá‡¶∏ ‡¶ï‡¶∞‡¶ø
                        channel_block_lines, new_i = process_channel_with_auto_updated(
                            lines, i, current_channel, new_urls, is_manual_run
                        )
                        
                        # ‡¶®‡¶§‡ßÅ‡¶® ‡¶≤‡¶æ‡¶á‡¶®‡¶ó‡ßÅ‡¶≤‡ßã ‡¶Ø‡ßã‡¶ó ‡¶ï‡¶∞‡¶ø
                        new_lines.extend(channel_block_lines)
                        
                        i = new_i
                        channels_updated += 1
                        print(f"‚úÖ Updated {current_channel} with {len(new_urls)} new URLs")
                    else:
                        print(f"‚ö†Ô∏è No new URLs found for {current_channel}, keeping as is")
                        # ‡¶®‡¶§‡ßÅ‡¶® URL ‡¶®‡¶æ ‡¶•‡¶æ‡¶ï‡¶≤‡ßá ‡¶™‡ßÅ‡¶∞‡ßã ‡¶ö‡ßç‡¶Ø‡¶æ‡¶®‡ßá‡¶≤ ‡¶¨‡ßç‡¶≤‡¶ï ‡¶Ö‡¶™‡¶∞‡¶ø‡¶¨‡¶∞‡ßç‡¶§‡¶ø‡¶§ ‡¶∞‡¶æ‡¶ñ‡¶ø
                        end_idx = i
                        for j in range(i + 1, len(lines)):
                            if lines[j].startswith('#EXTINF:'):
                                end_idx = j - 1
                                break
                            if j == len(lines) - 1:
                                end_idx = j
                                break
                        
                        for j in range(i, end_idx + 1):
                            new_lines.append(lines[j])
                        
                        i = end_idx
                else:
                    # ‡¶Æ‡ßç‡¶Ø‡¶æ‡¶™ ‡¶ï‡¶∞‡¶æ ‡¶ö‡ßç‡¶Ø‡¶æ‡¶®‡ßá‡¶≤ ‡¶®‡¶æ ‡¶π‡¶≤‡ßá ‡¶Ö‡¶™‡¶∞‡¶ø‡¶¨‡¶∞‡ßç‡¶§‡¶ø‡¶§ ‡¶∞‡¶æ‡¶ñ‡¶ø
                    new_lines.append(line)
            else:
                # EXTINF ‡¶≤‡¶æ‡¶á‡¶® ‡¶®‡¶æ ‡¶π‡¶≤‡ßá ‡¶Ö‡¶™‡¶∞‡¶ø‡¶¨‡¶∞‡ßç‡¶§‡¶ø‡¶§ ‡¶∞‡¶æ‡¶ñ‡¶ø
                new_lines.append(line)
            
            i += 1
        
        # ‡¶®‡¶§‡ßÅ‡¶® ‡¶ï‡¶®‡ßç‡¶ü‡ßá‡¶®‡ßç‡¶ü ‡¶§‡ßà‡¶∞‡¶ø ‡¶ï‡¶∞‡¶ø
        updated_content = '\n'.join(new_lines)
        
        # ‡¶Ü‡¶™‡¶°‡ßá‡¶ü ‡¶ï‡¶∞‡¶æ ‡¶ï‡¶®‡ßç‡¶ü‡ßá‡¶®‡ßç‡¶ü ‡¶∏‡ßá‡¶≠ ‡¶ï‡¶∞‡ßÅ‡¶®
        with open('sirometv_updated.m3u', 'w', encoding='utf-8') as f:
            f.write(updated_content)
        
        # ‡¶≠‡ßá‡¶∞‡¶ø‡¶´‡¶ø‡¶ï‡ßá‡¶∂‡¶®
        print(f"\n{'='*50}")
        print(f"üéâ Update Summary:")
        print(f"   Run type: {'Manual' if is_manual_run else 'Scheduled'}")
        print(f"   Total mapped channels: {len(CHANNEL_MAPPING)}")
        print(f"   Channels updated: {channels_updated}")
        
        # ‡¶Ü‡¶∏‡¶≤ ‡¶è‡¶¨‡¶Ç ‡¶Ü‡¶™‡¶°‡ßá‡¶ü‡ßá‡¶° ‡¶ï‡¶®‡ßç‡¶ü‡ßá‡¶®‡ßç‡¶ü ‡¶§‡ßÅ‡¶≤‡¶®‡¶æ
        original_lines = main_content.split('\n')
        updated_lines = updated_content.split('\n')
        
        print(f"\nüìä File Comparison:")
        print(f"   Original lines: {len(original_lines)}")
        print(f"   Updated lines:  {len(updated_lines)}")
        
        # T Sports ‡¶∏‡ßá‡¶ï‡¶∂‡¶® ‡¶ö‡ßá‡¶ï
        print(f"\nüîç Verifying T Sports section:")
        
        # ‡¶Ü‡¶∏‡¶≤ T Sports ‡¶∏‡ßá‡¶ï‡¶∂‡¶®‡ßá ‡¶ï‡¶§‡¶ó‡ßÅ‡¶≤‡ßã ‡¶≤‡¶ø‡¶Ç‡¶ï ‡¶õ‡¶ø‡¶≤
        in_t_sports = False
        original_links = []
        for line in original_lines:
            if 'T Sports' in line and line.startswith('#EXTINF:'):
                in_t_sports = True
                continue
            if in_t_sports and line.startswith('#EXTINF:'):
                break
            if in_t_sports and (line.startswith('http://') or line.startswith('https://')):
                original_links.append(line)
        
        # ‡¶Ü‡¶™‡¶°‡ßá‡¶ü‡ßá‡¶° T Sports ‡¶∏‡ßá‡¶ï‡¶∂‡¶®‡ßá ‡¶ï‡¶§‡¶ó‡ßÅ‡¶≤‡ßã ‡¶≤‡¶ø‡¶Ç‡¶ï ‡¶Ü‡¶õ‡ßá
        in_t_sports = False
        updated_links = []
        for line in updated_lines:
            if 'T Sports' in line and line.startswith('#EXTINF:'):
                in_t_sports = True
                continue
            if in_t_sports and line.startswith('#EXTINF:'):
                break
            if in_t_sports and (line.startswith('http://') or line.startswith('https://')):
                updated_links.append(line)
        
        print(f"   Original T Sports links: {len(original_links)}")
        print(f"   Updated T Sports links:  {len(updated_links)}")
        
        if len(updated_links) >= len(original_links):
            print(f"   ‚úÖ SUCCESS: All original links preserved!")
            
            # ‡¶Ü‡¶∏‡¶≤ ‡¶≤‡¶ø‡¶Ç‡¶ï‡¶ó‡ßÅ‡¶≤‡ßã ‡¶Ü‡¶õ‡ßá ‡¶ï‡¶ø‡¶®‡¶æ ‡¶ö‡ßá‡¶ï
            missing_links = []
            for orig_link in original_links:
                if orig_link not in updated_links:
                    missing_links.append(orig_link)
            
            if missing_links:
                print(f"   ‚ö†Ô∏è WARNING: {len(missing_links)} original links missing!")
                for link in missing_links[:3]:
                    print(f"      - {link[:60]}...")
            else:
                print(f"   ‚úÖ Perfect: All {len(original_links)} original links are preserved")
        else:
            print(f"   ‚ùå ERROR: {len(original_links) - len(updated_links)} links lost!")
        
        # T Sports ‡¶∏‡ßá‡¶ï‡¶∂‡¶® ‡¶¶‡ßá‡¶ñ‡¶æ‡¶®
        print(f"\nüìã T Sports section in updated file (first 25 lines after EXTINF):")
        in_section = False
        count = 0
        
        for line in updated_lines:
            if 'T Sports' in line and line.startswith('#EXTINF:'):
                in_section = True
                print(f"   [EXTINF]: {line}")
                count += 1
                continue
            
            if in_section:
                if line.startswith('#EXTINF:'):
                    break
                
                if count < 25:
                    if line.strip() == '':
                        print(f"   [EMPTY LINE]")
                    else:
                        print(f"   {line}")
                    count += 1
        
        EOF
        
    - name: Verify and replace playlist
      run: |
        echo "üîç Verifying updated playlist..."
        
        if [ ! -f "sirometv_updated.m3u" ] || [ ! -s "sirometv_updated.m3u" ]; then
          echo "‚ùå ERROR: Updated playlist is missing or empty!"
          exit 1
        fi
        
        # T Sports ‡¶∏‡ßá‡¶ï‡¶∂‡¶®‡ßá ‡¶Ü‡¶∏‡¶≤ ‡¶≤‡¶ø‡¶Ç‡¶ï ‡¶Ü‡¶õ‡ßá ‡¶ï‡¶ø‡¶®‡¶æ ‡¶ö‡ßá‡¶ï
        echo "üîç Checking if original links are preserved in T Sports:"
        
        # ‡¶Ü‡¶∏‡¶≤ ‡¶´‡¶æ‡¶á‡¶≤‡ßá T Sports ‡¶è‡¶∞ ‡¶≤‡¶ø‡¶Ç‡¶ï‡¶ó‡ßÅ‡¶≤‡ßã
        echo "   Original links in T Sports section:"
        awk '/T Sports/{p=1} p&&/^#EXTINF:/&&!/T Sports/{p=0} p&&/^http/{print "     - "$0}' main_playlist.m3u | head -10
        
        # ‡¶Ü‡¶™‡¶°‡ßá‡¶ü‡ßá‡¶° ‡¶´‡¶æ‡¶á‡¶≤‡ßá T Sports ‡¶è‡¶∞ ‡¶≤‡¶ø‡¶Ç‡¶ï‡¶ó‡ßÅ‡¶≤‡ßã
        echo "   Updated links in T Sports section:"
        awk '/T Sports/{p=1} p&&/^#EXTINF:/&&!/T Sports/{p=0} p&&/^http/{print "     - "$0}' sirometv_updated.m3u | head -10
        
        # ‡¶≤‡¶ø‡¶Ç‡¶ï ‡¶∏‡¶Ç‡¶ñ‡ßç‡¶Ø‡¶æ ‡¶§‡ßÅ‡¶≤‡¶®‡¶æ
        ORIG_TS_LINKS=$(awk '/T Sports/{p=1} p&&/^#EXTINF:/&&!/T Sports/{p=0} p&&/^http/{count++} END{print count}' main_playlist.m3u)
        UPD_TS_LINKS=$(awk '/T Sports/{p=1} p&&/^#EXTINF:/&&!/T Sports/{p=0} p&&/^http/{count++} END{print count}' sirometv_updated.m3u)
        
        echo ""
        echo "üìä T Sports link count comparison:"
        echo "   Original: $ORIG_TS_LINKS links"
        echo "   Updated:  $UPD_TS_LINKS links"
        
        if [ "$UPD_TS_LINKS" -ge "$ORIG_TS_LINKS" ]; then
          echo "   ‚úÖ All original links preserved!"
        else
          echo "   ‚ùå ERROR: $((ORIG_TS_LINKS - UPD_TS_LINKS)) links lost!"
        fi
        
        # Show T Sports section structure
        echo ""
        echo "üîç T Sports section structure:"
        grep -n -B1 -A 15 "T Sports" sirometv_updated.m3u | head -25
        
        # Count AUTO-UPDATED sections
        AUTO_COUNT=$(grep -c "#AUTO-UPDATED" sirometv_updated.m3u || true)
        echo ""
        echo "üìä AUTO-UPDATED sections: $AUTO_COUNT"
        
        mv sirometv_updated.m3u sirometv.m3u
        
    - name: Commit and push changes
      run: |
        echo "üíæ Saving changes to repository..."
        
        git config user.name "github-actions[bot]"
        git config user.email "github-actions[bot]@users.noreply.github.com"
        git add sirometv.m3u
        
        if git diff --staged --quiet; then
          echo "‚úÖ No changes detected - playlist is up to date"
        else
          # ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ‡¶¶‡ßá‡¶∂‡ßá‡¶∞ ‡¶∏‡¶Æ‡ßü ‡¶®‡ßá‡¶ì‡ßü‡¶æ (BD Time format)
          BANGLADESH_TIME=$(TZ='Asia/Dhaka' date +'%Y-%m-%d %I:%M:%S%p BD Time')
          
          # Check if manual or scheduled run
          if [ "${{ github.event_name }}" == "workflow_dispatch" ]; then
            git commit -m "üîÑ Manual Update: Preserved ALL Original Links - $BANGLADESH_TIME"
          else
            git commit -m "üîÑ Scheduled Update: Preserved ALL Original Links - $BANGLADESH_TIME"
          fi
          git push
          echo "üéâ Successfully updated while preserving ALL original links!"
        fi
        
    - name: Cleanup
      run: |
        rm -f main_playlist.m3u source_playlist.m3u
        echo "‚úÖ Cleanup completed!"
