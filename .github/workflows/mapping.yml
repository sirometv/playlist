name: Mapping

on:
  schedule:
    - cron: '*/5 * * * *'
  workflow_dispatch:

permissions:
  contents: write

jobs:
  sync-channels:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
        
    - name: Download playlists
      run: |
        echo "üì• Downloading playlists..."
        curl -s -L -o main_playlist.m3u "https://raw.githubusercontent.com/sirometv/playlist/main/sirometv.m3u"
        curl -s -L -o source_playlist.m3u "https://raw.githubusercontent.com/sirometv/playlist/main/Ayna.m3u"
        
        for file in main_playlist.m3u source_playlist.m3u; do
          if [ ! -f "$file" ] || [ ! -s "$file" ]; then
            echo "‚ùå ERROR: $file download failed!"
            exit 1
          fi
          LINES=$(wc -l < "$file")
          echo "‚úÖ $file downloaded - $LINES lines"
        done
        
    - name: Update All Channel
      run: |
        echo "üîÑ Updating All Channel..."
        
        python3 - << 'EOF'
        import re
        from datetime import datetime
        import pytz
        
        # ‡¶ö‡ßç‡¶Ø‡¶æ‡¶®‡ßá‡¶≤ ‡¶Æ‡ßç‡¶Ø‡¶æ‡¶™‡¶ø‡¶Ç - ‡¶Æ‡ßá‡¶á‡¶® ‡¶ö‡ßç‡¶Ø‡¶æ‡¶®‡ßá‡¶≤‡ßá‡¶∞ ‡¶®‡¶æ‡¶Æ : [‡¶∏‡ßã‡¶∞‡ßç‡¶∏ ‡¶ö‡ßç‡¶Ø‡¶æ‡¶®‡ßá‡¶≤‡ßá‡¶∞ exact keywords]
        CHANNEL_MAPPING = {
                        "BTV National": ["BTV NATIONAL HD", "BTV World"],
            "BTV CTG": ["BTV CTG"],
            "Somoy TV": ["Somoy News TV", "Somoy TV"],
            "Jamuna TV": ["Jamuna TV","JAMUNA TV"],
            "Ekushey TV": ["Ekushey TV"],
            "NTV BD": ["NTV"],
            "NTV-Europe": ["NTV Europe"],
            "Channel 24": ["Channel 24"],
            "Deen TV": ["Deen TV"],
            "SATV": ["SA TV"],
            "GTV": ["Gazi TV"],
            "T Sports": ["T Sports HD", "A Sports", "PTV Sports"],
            "Channel 9": ["Channel 9"],
            "Channel I": ["Channel I"],
            "Bangla Vision": ["Bangla Vision"],
            "News 24": ["News 24 BD"], 
            "Boishakhi TV": ["Boishakhi TV"],
            "Bijoy TV": ["Bijoy TV"],
            "ATN Bangla": ["ATN Bangla"],
            "ATN-Bangla News": ["ATN News"],
            "DBC News": ["DBC News"],
            "Independent TV": ["Independent TV"],
            "Bangla TV": ["Bangla TV"],
            "Desh TV": ["Desh TV"],
            "RTV": ["RTV"],
            "My TV": ["My TV"],
            "Ekattor TV": ["Ekattor TV"],
            "Peace TV Bangla": ["Peace TV Bangla HD"],
            "Rongeen TV": ["Rongeen TV"],
            "Gaan Bangla": ["Gaan Bangla", "GAAN BANGLA", "gaan bangla", "Gaan", "GAAN"],
            "Star Jalsha": ["Star Jalsha HD", "Star Jalsha"],
            "Star-Jalsha Movies": ["Star Jalsha Movies HD"],
            "Zee Bangla": ["Zee Bangla International", "Zee Bangla"],
            "Zee-Bangla Cinema": ["Zee Bangla Cinema"],
            # "Somoy TV": ["Somoy News TV", "Somoy TV"],
            # ‡¶è‡¶ñ‡¶æ‡¶®‡ßá ‡¶Ü‡¶™‡¶®‡¶ø ‡¶Ü‡¶∞‡ßã ‡¶ö‡ßç‡¶Ø‡¶æ‡¶®‡ßá‡¶≤ ‡¶Ø‡ßã‡¶ó ‡¶ï‡¶∞‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡¶¨‡ßá‡¶®
            # "Channel Name in Main": ["exact_keyword1", "exact_keyword2", "exact_keyword3"]
        }
        
        def get_bangladesh_time():
            """‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ‡¶¶‡ßá‡¶∂‡ßá‡¶∞ ‡¶¨‡¶∞‡ßç‡¶§‡¶Æ‡¶æ‡¶® ‡¶∏‡¶Æ‡¶Ø‡¶º ‡¶∞‡¶ø‡¶ü‡¶æ‡¶∞‡ßç‡¶® ‡¶ï‡¶∞‡ßá"""
            bangladesh_tz = pytz.timezone('Asia/Dhaka')
            now = datetime.now(bangladesh_tz)
            return now.strftime("%Y-%m-%d %I:%M:%S%p BD Time") + " üîÑ"
        
        def find_channel_urls(source_file, keywords):
            """‡¶∏‡ßã‡¶∞‡ßç‡¶∏ ‡¶™‡ßç‡¶≤‡ßá‡¶≤‡¶ø‡¶∏‡ßç‡¶ü ‡¶•‡ßá‡¶ï‡ßá ‡¶è‡¶ï‡¶æ‡¶ß‡¶ø‡¶ï ‡¶ö‡ßç‡¶Ø‡¶æ‡¶®‡ßá‡¶≤‡ßá‡¶∞ URL ‡¶ñ‡ßÅ‡¶Å‡¶ú‡ßá ‡¶¨‡ßá‡¶∞ ‡¶ï‡¶∞‡ßá"""
            with open(source_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
            urls = []
            
            # ‡¶∏‡ßã‡¶∞‡ßç‡¶∏ ‡¶™‡ßç‡¶≤‡ßá‡¶≤‡¶ø‡¶∏‡ßç‡¶ü‡¶ï‡ßá ‡¶≤‡¶æ‡¶á‡¶®‡ßá ‡¶≠‡¶æ‡¶ó ‡¶ï‡¶∞‡ßÅ‡¶®
            lines = content.split('\n')
            i = 0
            
            while i < len(lines):
                line = lines[i]
                # EXTINF ‡¶≤‡¶æ‡¶á‡¶® ‡¶ñ‡ßÅ‡¶Å‡¶ú‡ßÅ‡¶®
                if line.startswith('#EXTINF:'):
                    extinf_line = line
                    channel_name_part = extinf_line.split(',', 1)[1] if ',' in extinf_line else ""
                    
                    # ‡¶™‡¶∞‡ßá‡¶∞ ‡¶≤‡¶æ‡¶á‡¶® URL ‡¶π‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡ßá
                    if i + 1 < len(lines) and lines[i + 1].startswith('http'):
                        url_line = lines[i + 1]
                        
                        # ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶ü‡¶ø keyword ‡¶è‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶ö‡ßá‡¶ï ‡¶ï‡¶∞‡ßÅ‡¶®
                        for keyword in keywords:
                            # Exact match ‡¶ö‡ßá‡¶ï - keyword ‡¶ö‡ßç‡¶Ø‡¶æ‡¶®‡ßá‡¶≤ ‡¶®‡¶æ‡¶Æ‡ßá‡¶∞ ‡¶Æ‡¶ß‡ßç‡¶Ø‡ßá exact match ‡¶π‡¶§‡ßá ‡¶π‡¶¨‡ßá
                            # Case insensitive match
                            pattern = r'\b' + re.escape(keyword) + r'\b'
                            if re.search(pattern, channel_name_part, re.IGNORECASE):
                                print(f"‚úÖ Exact match found: '{keyword}' in '{channel_name_part}'")
                                urls.append((keyword, url_line.strip()))
                                break  # ‡¶è‡¶ï‡¶¨‡¶æ‡¶∞ ‡¶Æ‡ßç‡¶Ø‡¶æ‡¶ö ‡¶™‡ßá‡¶≤‡ßá ‡¶™‡¶∞‡ßá‡¶∞ keyword ‡¶ö‡ßá‡¶ï ‡¶ï‡¶∞‡¶æ‡¶∞ ‡¶¶‡¶∞‡¶ï‡¶æ‡¶∞ ‡¶®‡ßá‡¶á
                        i += 2  # EXTINF ‡¶è‡¶¨‡¶Ç URL ‡¶≤‡¶æ‡¶á‡¶® ‡¶∏‡ßç‡¶ï‡¶ø‡¶™ ‡¶ï‡¶∞‡ßÅ‡¶®
                    else:
                        i += 1
                else:
                    i += 1
            
            # ‡¶Ø‡¶¶‡¶ø ‡¶ï‡ßã‡¶®‡ßã URL ‡¶®‡¶æ ‡¶™‡¶æ‡¶ì‡ßü‡¶æ ‡¶Ø‡¶æ‡ßü, ‡¶§‡¶æ‡¶π‡¶≤‡ßá backup method ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡ßÅ‡¶®
            if not urls:
                for keyword in keywords:
                    # Backup regex method
                    pattern = rf'#EXTINF:-1[^,]*,[^,]*\b{re.escape(keyword)}\b[^\n]*\n(http[^\n]+)'
                    match = re.search(pattern, content, re.IGNORECASE)
                    if match:
                        url = match.group(1).strip()
                        print(f"‚úÖ Backup method found: '{keyword}' -> {url[:80]}...")
                        urls.append((keyword, url))
            
            if urls:
                print(f"‚úÖ Total URLs found: {len(urls)}")
            else:
                print(f"‚ùå No URLs found for keywords: {keywords}")
            
            return urls
        
        def extract_original_links(content, channel_name):
            """EXTINF ‡¶≤‡¶æ‡¶á‡¶®‡ßá‡¶∞ ‡¶™‡¶∞‡¶¨‡¶∞‡ßç‡¶§‡ßÄ ‡¶∏‡¶Æ‡¶∏‡ßç‡¶§ ‡¶Ü‡¶∏‡¶≤ ‡¶≤‡¶ø‡¶Ç‡¶ï ‡¶è‡¶¨‡¶Ç ‡¶ï‡¶Æ‡ßá‡¶®‡ßç‡¶ü‡ßá‡¶° ‡¶≤‡¶ø‡¶Ç‡¶ï‡¶ó‡ßÅ‡¶≤‡ßã ‡¶Ü‡¶≤‡¶æ‡¶¶‡¶æ ‡¶ï‡¶∞‡ßá"""
            # Pattern: EXTINF ‡¶≤‡¶æ‡¶á‡¶® ‡¶è‡¶¨‡¶Ç ‡¶§‡¶æ‡¶∞‡¶™‡¶∞ ‡¶Ø‡¶§‡¶ó‡ßÅ‡¶≤‡ßã ‡¶≤‡¶ø‡¶Ç‡¶ï ‡¶Ü‡¶õ‡ßá (AUTO-UPDATED ‡¶õ‡¶æ‡ßú‡¶æ)
            pattern = r'(#EXTINF:-1[^\n]*{}[^\n]*\n)((?:(?!#EXTINF|#AUTO-UPDATED).*\n)*)'.format(re.escape(channel_name))
            
            match = re.search(pattern, content, re.IGNORECASE)
            if not match:
                return [], []
            
            extinf_line = match.group(1)
            following_content = match.group(2)
            
            # ‡¶≤‡¶ø‡¶Ç‡¶ï‡¶ó‡ßÅ‡¶≤‡ßã ‡¶≤‡¶æ‡¶á‡¶®‡ßá ‡¶≠‡¶æ‡¶ó ‡¶ï‡¶∞‡ßÅ‡¶®
            lines = following_content.split('\n')
            
            original_links = []  # ‡¶Ü‡¶∏‡¶≤ ‡¶≤‡¶ø‡¶Ç‡¶ï (http/https, ‡¶ï‡¶Æ‡ßá‡¶®‡ßç‡¶ü ‡¶®‡ßü)
            commented_links = []  # ‡¶ï‡¶Æ‡ßá‡¶®‡ßç‡¶ü‡ßá‡¶° ‡¶≤‡¶ø‡¶Ç‡¶ï (# ‡¶¶‡¶ø‡ßü‡ßá ‡¶∂‡ßÅ‡¶∞‡ßÅ)
            other_lines = []  # ‡¶Ö‡¶®‡ßç‡¶Ø‡¶æ‡¶®‡ßç‡¶Ø ‡¶≤‡¶æ‡¶á‡¶®
            
            for line in lines:
                line = line.strip()
                if not line:
                    continue
                elif line.startswith('http://') or line.startswith('https://'):
                    original_links.append(line)
                elif line.startswith('#'):
                    if line.startswith('#http://') or line.startswith('#https://'):
                        commented_links.append(line)
                    else:
                        other_lines.append(line)
                else:
                    other_lines.append(line)
            
            print(f"üìä Extracted for {channel_name}:")
            print(f"   - Original links: {len(original_links)}")
            print(f"   - Commented links: {len(commented_links)}")
            print(f"   - Other lines: {len(other_lines)}")
            
            return original_links, commented_links
        
        def update_channel_structure(main_content, channel_name, channel_urls):
            """‡¶ö‡ßç‡¶Ø‡¶æ‡¶®‡ßá‡¶≤‡ßá‡¶∞ ‡¶∏‡¶Æ‡ßç‡¶™‡ßÇ‡¶∞‡ßç‡¶£ ‡¶∏‡ßç‡¶ü‡ßç‡¶∞‡¶æ‡¶ï‡¶ö‡¶æ‡¶∞ ‡¶Ü‡¶™‡¶°‡ßá‡¶ü ‡¶ï‡¶∞‡ßá"""
            if not channel_urls:
                print(f"‚ö†Ô∏è No URLs to update for {channel_name}")
                return main_content
            
            timestamp = get_bangladesh_time()
            
            # ‡¶Ü‡¶∏‡¶≤ ‡¶≤‡¶ø‡¶Ç‡¶ï ‡¶è‡¶¨‡¶Ç ‡¶ï‡¶Æ‡ßá‡¶®‡ßç‡¶ü‡ßá‡¶° ‡¶≤‡¶ø‡¶Ç‡¶ï‡¶ó‡ßÅ‡¶≤‡ßã ‡¶è‡¶ï‡ßç‡¶∏‡¶ü‡ßç‡¶∞‡¶æ‡¶ï‡ßç‡¶ü ‡¶ï‡¶∞‡ßÅ‡¶®
            original_links, commented_links = extract_original_links(main_content, channel_name)
            
            # URL ‡¶∏‡¶Ç‡¶ñ‡ßç‡¶Ø‡¶æ ‡¶Ö‡¶®‡ßÅ‡¶Ø‡¶æ‡¶Ø‡¶º‡ßÄ üîÑ ‡¶á‡¶Æ‡ßã‡¶ú‡¶ø ‡¶§‡ßà‡¶∞‡¶ø ‡¶ï‡¶∞‡ßÅ‡¶®
            refresh_emoji = "üîÑ" * len(channel_urls)
            
            # ‡¶ü‡¶æ‡¶á‡¶Æ‡¶∏‡ßç‡¶ü‡ßç‡¶Ø‡¶æ‡¶Æ‡ßç‡¶™‡ßá ‡¶á‡¶Æ‡ßã‡¶ú‡¶ø ‡¶Ø‡ßã‡¶ó ‡¶ï‡¶∞‡ßÅ‡¶®
            timestamp_with_emoji = f"{timestamp.split(' üîÑ')[0]} {refresh_emoji}"
            
            # ‡¶®‡¶§‡ßÅ‡¶® ‡¶∏‡ßç‡¶ü‡ßç‡¶∞‡¶æ‡¶ï‡¶ö‡¶æ‡¶∞ ‡¶§‡ßà‡¶∞‡¶ø ‡¶ï‡¶∞‡ßÅ‡¶®
            new_structure = f"#EXTINF:-1 tvg-logo=\"https://i.postimg.cc/KcwPJkXB/resized-300x180-transparent.png\" group-title=\"Bangladeshi\", {channel_name}\n"
            
            # AUTO-UPDATED ‡¶∏‡ßá‡¶ï‡¶∂‡¶® ‡¶Ø‡ßã‡¶ó ‡¶ï‡¶∞‡ßÅ‡¶®
            new_structure += f"#AUTO-UPDATED - {channel_name} - {timestamp_with_emoji}\n"
            
            # ‡¶®‡¶§‡ßÅ‡¶® ‡¶™‡¶æ‡¶ì‡ßü‡¶æ URL ‡¶ó‡ßÅ‡¶≤‡ßã ‡¶Ø‡ßã‡¶ó ‡¶ï‡¶∞‡ßÅ‡¶®
            for keyword, url in channel_urls:
                new_structure += f"{url}\n"
            
            # Main-Playlist ‡¶∏‡ßá‡¶ï‡¶∂‡¶® ‡¶Ø‡ßã‡¶ó ‡¶ï‡¶∞‡ßÅ‡¶®
            if original_links:
                new_structure += f"#Main-Playlist - Keep Alive üü°\n"
                for link in original_links:
                    new_structure += f"{link}\n"
            
            # ‡¶ï‡¶Æ‡ßá‡¶®‡ßç‡¶ü‡ßá‡¶° ‡¶≤‡¶ø‡¶Ç‡¶ï‡¶ó‡ßÅ‡¶≤‡ßã ‡¶Ø‡ßã‡¶ó ‡¶ï‡¶∞‡ßÅ‡¶®
            if commented_links:
                for link in commented_links:
                    new_structure += f"{link}\n"
            
            print(f"üìù Rebuilding structure for {channel_name}")
            print(f"   - New URLs: {len(channel_urls)}")
            print(f"   - Original links kept: {len(original_links)}")
            print(f"   - Commented links kept: {len(commented_links)}")
            
            # ‡¶™‡ßÅ‡¶∞‡¶æ‡¶§‡¶® ‡¶ö‡ßç‡¶Ø‡¶æ‡¶®‡ßá‡¶≤ ‡¶¨‡ßç‡¶≤‡¶ï ‡¶∞‡¶ø‡¶™‡ßç‡¶≤‡ßá‡¶∏ ‡¶ï‡¶∞‡ßÅ‡¶®
            # Pattern: EXTINF ‡¶≤‡¶æ‡¶á‡¶® ‡¶•‡ßá‡¶ï‡ßá ‡¶™‡¶∞‡¶¨‡¶∞‡ßç‡¶§‡ßÄ EXTINF ‡¶¨‡¶æ ‡¶´‡¶æ‡¶á‡¶≤ ‡¶∂‡ßá‡¶∑ ‡¶™‡¶∞‡ßç‡¶Ø‡¶®‡ßç‡¶§
            pattern = r'(#EXTINF:-1[^\n]*{}[^\n]*\n)(.*?)(?=\n#EXTINF:-1|\Z)'.format(re.escape(channel_name))
            
            if re.search(pattern, main_content, re.IGNORECASE | re.DOTALL):
                def replacement(match):
                    return new_structure.rstrip() + '\n'
                
                updated_content = re.sub(pattern, replacement, main_content, flags=re.IGNORECASE | re.DOTALL)
                print(f"‚úÖ Rebuilt structure for {channel_name}")
                return updated_content
            else:
                print(f"‚ùå Could not find {channel_name} in main playlist")
                return main_content
        
        # ‡¶Æ‡ßá‡¶á‡¶® ‡¶™‡ßç‡¶≤‡ßá‡¶≤‡¶ø‡¶∏‡ßç‡¶ü ‡¶≤‡ßã‡¶° ‡¶ï‡¶∞‡ßÅ‡¶®
        with open('main_playlist.m3u', 'r', encoding='utf-8') as f:
            main_content = f.read()
        
        # Check if manual run or scheduled
        import os
        is_manual_run = os.environ.get('GITHUB_EVENT_NAME') == 'workflow_dispatch'
        
        updated_content = main_content
        total_urls_found = 0
        channels_updated = 0
        
        print(f"üìä Run type: {'Manual' if is_manual_run else 'Scheduled'}")
        
        # ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶ü‡¶ø ‡¶ö‡ßç‡¶Ø‡¶æ‡¶®‡ßá‡¶≤‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶Ü‡¶™‡¶°‡ßá‡¶ü ‡¶ï‡¶∞‡ßÅ‡¶®
        for main_channel, search_keywords in CHANNEL_MAPPING.items():
            print(f"\n{'='*50}")
            print(f"üîç Processing: {main_channel}")
            print(f"   Searching for exact keywords: {search_keywords}")
            
            # ‡¶è‡¶ï‡¶æ‡¶ß‡¶ø‡¶ï URL ‡¶ñ‡ßÅ‡¶Å‡¶ú‡ßÅ‡¶®
            channel_urls = find_channel_urls('source_playlist.m3u', search_keywords)
            
            if channel_urls:
                print(f"   Found {len(channel_urls)} URLs: {[keyword for keyword, _ in channel_urls]}")
                updated_content = update_channel_structure(updated_content, main_channel, channel_urls)
                total_urls_found += len(channel_urls)
                channels_updated += 1
            else:
                print(f"‚ö†Ô∏è No URLs found for {main_channel}")
                
                # ‡¶ö‡ßá‡¶ï ‡¶ï‡¶∞‡ßÅ‡¶® ‡¶Ø‡ßá ‡¶ö‡ßç‡¶Ø‡¶æ‡¶®‡ßá‡¶≤‡¶ü‡¶ø ‡¶Æ‡ßá‡¶á‡¶® ‡¶™‡ßç‡¶≤‡ßá‡¶≤‡¶ø‡¶∏‡ßç‡¶ü‡ßá ‡¶Ü‡¶õ‡ßá ‡¶ï‡¶ø‡¶®‡¶æ
                pattern_extinf = r'#EXTINF:-1[^\n]*{}[^\n]*'.format(re.escape(main_channel))
                if re.search(pattern_extinf, main_content, re.IGNORECASE):
                    print(f"   ‚ÑπÔ∏è Channel '{main_channel}' exists in main playlist but no URLs found in source")
        
        # ‡¶Ü‡¶™‡¶°‡ßá‡¶ü ‡¶ï‡¶∞‡¶æ ‡¶ï‡¶®‡ßç‡¶ü‡ßá‡¶®‡ßç‡¶ü ‡¶∏‡ßá‡¶≠ ‡¶ï‡¶∞‡ßÅ‡¶®
        with open('sirometv_updated.m3u', 'w', encoding='utf-8') as f:
            f.write(updated_content)
        
        print(f"\n{'='*50}")
        print(f"üéâ Update Summary:")
        print(f"   Run type: {'Manual' if is_manual_run else 'Scheduled'}")
        print(f"   Total channels processed: {len(CHANNEL_MAPPING)}")
        print(f"   Channels successfully updated: {channels_updated}")
        print(f"   Total URLs updated: {total_urls_found}")
        
        # BTV National ‡¶∏‡ßá‡¶ï‡¶∂‡¶® ‡¶¶‡ßá‡¶ñ‡¶æ‡¶® (‡¶°‡¶ø‡¶¨‡¶æ‡¶ó‡¶ø‡¶Ç ‡¶è‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø)
        print(f"\nüìã Sample of updated BTV National section:")
        btv_pattern = r'(#EXTINF:-1[^\n]*BTV National[^\n]*\n)(.*?)(?=\n#EXTINF:-1|\Z)'
        match_sample = re.search(btv_pattern, updated_content, re.IGNORECASE | re.DOTALL)
        if match_sample:
            sample_content = match_sample.group(0)
            sample_lines = sample_content.split('\n')
            for i, line in enumerate(sample_lines[:15]):
                print(f"   {i+1}: {line}")
            if len(sample_lines) > 15:
                print(f"   ... and {len(sample_lines) - 15} more lines")
        
        EOF
        
    - name: Verify and replace playlist
      run: |
        echo "üîç Verifying updated playlist..."
        
        if [ ! -f "sirometv_updated.m3u" ] || [ ! -s "sirometv_updated.m3u" ]; then
          echo "‚ùå ERROR: Updated playlist is missing or empty!"
          exit 1
        fi
        
        # Check for AUTO-UPDATED entries
        AUTO_COUNT=$(grep -c "#AUTO-UPDATED" sirometv_updated.m3u || true)
        echo "üìä AUTO-UPDATED entries found: $AUTO_COUNT"
        
        # Check for Keep Alive entries
        KEEP_ALIVE_COUNT=$(grep -c "#Main-Playlist - Keep Alive" sirometv_updated.m3u || true)
        echo "üìä Keep Alive sections found: $KEEP_ALIVE_COUNT"
        
        # Check for T Sports entries
        echo ""
        echo "üîç Checking T Sports entries..."
        grep -n -A 8 "T Sports" sirometv_updated.m3u | head -20 || echo "No T Sports found"
        
        # Check for BTV National entries
        echo ""
        echo "üîç Checking BTV National entries..."
        grep -n -A 12 "BTV National" sirometv_updated.m3u | head -25 || echo "No BTV National found"
        
        # Count total lines
        TOTAL_LINES=$(wc -l < sirometv_updated.m3u)
        echo ""
        echo "üìä Total lines in updated playlist: $TOTAL_LINES"
        
        mv sirometv_updated.m3u sirometv.m3u
        
    - name: Commit and push changes
      run: |
        echo "üíæ Saving changes to repository..."
        
        git config user.name "github-actions[bot]"
        git config user.email "github-actions[bot]@users.noreply.github.com"
        git add sirometv.m3u
        
        if git diff --staged --quiet; then
          echo "‚úÖ No changes detected - playlist is up to date"
        else
          # ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ‡¶¶‡ßá‡¶∂‡ßá‡¶∞ ‡¶∏‡¶Æ‡ßü ‡¶®‡ßá‡¶ì‡ßü‡¶æ (BD Time format)
          BANGLADESH_TIME=$(TZ='Asia/Dhaka' date +'%Y-%m-%d %I:%M:%S%p BD Time')
          
          # Check if manual or scheduled run
          if [ "${{ github.event_name }}" == "workflow_dispatch" ]; then
            git commit -m "üîÑ Manual Update: Rebuilt Channel Structure - $BANGLADESH_TIME"
          else
            git commit -m "üîÑ Scheduled Update: Rebuilt Channel Structure - $BANGLADESH_TIME"
          fi
          git push
          echo "üéâ Successfully updated channel structure!"
        fi
        
    - name: Cleanup
      run: |
        rm -f main_playlist.m3u source_playlist.m3u
        echo "‚úÖ Cleanup completed!"
