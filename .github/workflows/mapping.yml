name: Mapping

on:
  schedule:
    - cron: '*/5 * * * *'
  workflow_dispatch:

permissions:
  contents: write

jobs:
  sync-channels:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
        
    - name: Download playlists
      run: |
        echo "üì• Downloading playlists..."
        curl -s -L -o main_playlist.m3u "https://raw.githubusercontent.com/sirometv/playlist/main/sirometv.m3u"
        curl -s -L -o source_playlist.m3u "https://raw.githubusercontent.com/sirometv/playlist/main/Ayna.m3u"
        
        for file in main_playlist.m3u source_playlist.m3u; do
          if [ ! -f "$file" ] || [ ! -s "$file" ]; then
            echo "‚ùå ERROR: $file download failed!"
            exit 1
          fi
          LINES=$(wc -l < "$file")
          echo "‚úÖ $file downloaded - $LINES lines"
        done
        
    - name: Update All Channel
      run: |
        echo "üîÑ Updating All Channel..."
        
        python3 - << 'EOF'
        import re
        from datetime import datetime
        import pytz
        
        # ‡¶ö‡ßç‡¶Ø‡¶æ‡¶®‡ßá‡¶≤ ‡¶Æ‡ßç‡¶Ø‡¶æ‡¶™‡¶ø‡¶Ç - ‡¶Æ‡ßá‡¶á‡¶® ‡¶ö‡ßç‡¶Ø‡¶æ‡¶®‡ßá‡¶≤‡ßá‡¶∞ ‡¶®‡¶æ‡¶Æ : [‡¶∏‡ßã‡¶∞‡ßç‡¶∏ ‡¶ö‡ßç‡¶Ø‡¶æ‡¶®‡ßá‡¶≤‡ßá‡¶∞ exact keywords]
        CHANNEL_MAPPING = {
            "T Sports": ["T Sports HD", "A Sports", "PTV Sports"],
            "BTV National": ["BTV NATIONAL HD", "BTV World"],
            "BTV CTG": ["BTV CTG"],
            "Channel 9": ["Channel 9"],
            "Channel I": ["Channel I"],
            "Bangla Vision": ["Bangla Vision"],
            "News 24": ["News 24 BD"], 
            "Boishakhi TV": ["Boishakhi TV"],
            "Bijoy TV": ["Bijoy TV"],
            "ATN Bangla": ["ATN Bangla"],
            "ATN-Bangla News": ["ATN News"],
            "DBC News": ["DBC News"],
            "Independent TV": ["Independent TV"],
            "Bangla TV": ["Bangla TV"],
            "Desh TV": ["Desh TV"],
            "RTV": ["RTV"],
            "My TV": ["My TV"],
            # "Somoy TV": ["Somoy News TV", "Somoy TV"],
            # ‡¶è‡¶ñ‡¶æ‡¶®‡ßá ‡¶Ü‡¶™‡¶®‡¶ø ‡¶Ü‡¶∞‡ßã ‡¶ö‡ßç‡¶Ø‡¶æ‡¶®‡ßá‡¶≤ ‡¶Ø‡ßã‡¶ó ‡¶ï‡¶∞‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡¶¨‡ßá‡¶®
            # "Channel Name in Main": ["exact_keyword1", "exact_keyword2", "exact_keyword3"]
        }
        
        def get_bangladesh_time():
            """‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ‡¶¶‡ßá‡¶∂‡ßá‡¶∞ ‡¶¨‡¶∞‡ßç‡¶§‡¶Æ‡¶æ‡¶® ‡¶∏‡¶Æ‡¶Ø‡¶º ‡¶∞‡¶ø‡¶ü‡¶æ‡¶∞‡ßç‡¶® ‡¶ï‡¶∞‡ßá"""
            bangladesh_tz = pytz.timezone('Asia/Dhaka')
            now = datetime.now(bangladesh_tz)
            return now.strftime("%Y-%m-%d %I:%M:%S%p BD Time") + " üîÑ"
        
        def find_channel_urls(source_file, keywords):
            """‡¶∏‡ßã‡¶∞‡ßç‡¶∏ ‡¶™‡ßç‡¶≤‡ßá‡¶≤‡¶ø‡¶∏‡ßç‡¶ü ‡¶•‡ßá‡¶ï‡ßá ‡¶è‡¶ï‡¶æ‡¶ß‡¶ø‡¶ï ‡¶ö‡ßç‡¶Ø‡¶æ‡¶®‡ßá‡¶≤‡ßá‡¶∞ URL ‡¶ñ‡ßÅ‡¶Å‡¶ú‡ßá ‡¶¨‡ßá‡¶∞ ‡¶ï‡¶∞‡ßá"""
            with open(source_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
            urls = []
            
            # ‡¶∏‡ßã‡¶∞‡ßç‡¶∏ ‡¶™‡ßç‡¶≤‡ßá‡¶≤‡¶ø‡¶∏‡ßç‡¶ü‡¶ï‡ßá ‡¶≤‡¶æ‡¶á‡¶®‡ßá ‡¶≠‡¶æ‡¶ó ‡¶ï‡¶∞‡ßÅ‡¶®
            lines = content.split('\n')
            i = 0
            
            while i < len(lines):
                line = lines[i]
                # EXTINF ‡¶≤‡¶æ‡¶á‡¶® ‡¶ñ‡ßÅ‡¶Å‡¶ú‡ßÅ‡¶®
                if line.startswith('#EXTINF:'):
                    extinf_line = line
                    channel_name_part = extinf_line.split(',', 1)[1] if ',' in extinf_line else ""
                    
                    # ‡¶™‡¶∞‡ßá‡¶∞ ‡¶≤‡¶æ‡¶á‡¶® URL ‡¶π‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡ßá
                    if i + 1 < len(lines) and lines[i + 1].startswith('http'):
                        url_line = lines[i + 1]
                        
                        # ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶ü‡¶ø keyword ‡¶è‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶ö‡ßá‡¶ï ‡¶ï‡¶∞‡ßÅ‡¶®
                        for keyword in keywords:
                            # Exact match ‡¶ö‡ßá‡¶ï - keyword ‡¶ö‡ßç‡¶Ø‡¶æ‡¶®‡ßá‡¶≤ ‡¶®‡¶æ‡¶Æ‡ßá‡¶∞ ‡¶Æ‡¶ß‡ßç‡¶Ø‡ßá exact match ‡¶π‡¶§‡ßá ‡¶π‡¶¨‡ßá
                            # Case insensitive match
                            pattern = r'\b' + re.escape(keyword) + r'\b'
                            if re.search(pattern, channel_name_part, re.IGNORECASE):
                                print(f"‚úÖ Exact match found: '{keyword}' in '{channel_name_part}'")
                                urls.append((keyword, url_line.strip()))
                                break  # ‡¶è‡¶ï‡¶¨‡¶æ‡¶∞ ‡¶Æ‡ßç‡¶Ø‡¶æ‡¶ö ‡¶™‡ßá‡¶≤‡ßá ‡¶™‡¶∞‡ßá‡¶∞ keyword ‡¶ö‡ßá‡¶ï ‡¶ï‡¶∞‡¶æ‡¶∞ ‡¶¶‡¶∞‡¶ï‡¶æ‡¶∞ ‡¶®‡ßá‡¶á
                        i += 2  # EXTINF ‡¶è‡¶¨‡¶Ç URL ‡¶≤‡¶æ‡¶á‡¶® ‡¶∏‡ßç‡¶ï‡¶ø‡¶™ ‡¶ï‡¶∞‡ßÅ‡¶®
                    else:
                        i += 1
                else:
                    i += 1
            
            # ‡¶Ø‡¶¶‡¶ø ‡¶ï‡ßã‡¶®‡ßã URL ‡¶®‡¶æ ‡¶™‡¶æ‡¶ì‡ßü‡¶æ ‡¶Ø‡¶æ‡ßü, ‡¶§‡¶æ‡¶π‡¶≤‡ßá backup method ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡ßÅ‡¶®
            if not urls:
                for keyword in keywords:
                    # Backup regex method
                    pattern = rf'#EXTINF:-1[^,]*,[^,]*\b{re.escape(keyword)}\b[^\n]*\n(http[^\n]+)'
                    match = re.search(pattern, content, re.IGNORECASE)
                    if match:
                        url = match.group(1).strip()
                        print(f"‚úÖ Backup method found: '{keyword}' -> {url[:80]}...")
                        urls.append((keyword, url))
            
            if urls:
                print(f"‚úÖ Total URLs found: {len(urls)}")
            else:
                print(f"‚ùå No URLs found for keywords: {keywords}")
            
            return urls
        
        def update_channel_safely(main_content, channel_name, channel_urls):
            """‡¶è‡¶ï‡¶ü‡¶ø ‡¶ö‡ßç‡¶Ø‡¶æ‡¶®‡ßá‡¶≤ ‡¶Ü‡¶™‡¶°‡ßá‡¶ü ‡¶ï‡¶∞‡ßá ‡¶ï‡¶ø‡¶®‡ßç‡¶§‡ßÅ ‡¶™‡ßÅ‡¶∞‡¶æ‡¶®‡ßã ‡¶≤‡¶ø‡¶Ç‡¶ï‡¶ó‡ßÅ‡¶≤‡ßã ‡¶∏‡¶Ç‡¶∞‡¶ï‡ßç‡¶∑‡¶£ ‡¶ï‡¶∞‡ßá"""
            if not channel_urls:
                print(f"‚ö†Ô∏è No new URLs for {channel_name}, keeping everything as is")
                return main_content
            
            timestamp = get_bangladesh_time()
            refresh_emoji = "üîÑ" * len(channel_urls)
            timestamp_with_emoji = f"{timestamp.split(' üîÑ')[0]} {refresh_emoji}"
            
            print(f"üìù Updating {channel_name} with {len(channel_urls)} new URLs")
            print(f"   Keeping ALL original links intact")
            
            # ‡¶ö‡ßç‡¶Ø‡¶æ‡¶®‡ßá‡¶≤‡ßá‡¶∞ ‡¶™‡ßÅ‡¶∞‡ßã ‡¶¨‡ßç‡¶≤‡¶ï ‡¶ñ‡ßÅ‡¶Å‡¶ú‡ßÅ‡¶®
            pattern = r'(#EXTINF:-1[^\n]*{}[^\n]*\n)(.*?)(?=\n#EXTINF:-1|\Z)'.format(re.escape(channel_name))
            match = re.search(pattern, main_content, re.IGNORECASE | re.DOTALL)
            
            if not match:
                print(f"‚ùå Channel {channel_name} not found")
                return main_content
            
            extinf_line = match.group(1)
            rest_of_block = match.group(2)
            full_block = match.group(0)
            
            # ‡¶™‡ßÅ‡¶∞‡¶æ‡¶®‡ßã AUTO-UPDATED ‡¶∏‡ßá‡¶ï‡¶∂‡¶® ‡¶ñ‡ßÅ‡¶Å‡¶ú‡ßÅ‡¶®
            auto_updated_pattern = r'(#AUTO-UPDATED[^\n]*\n)((?:http[^\n]*\n)*)'
            auto_match = re.search(auto_updated_pattern, rest_of_block)
            
            # ‡¶®‡¶§‡ßÅ‡¶® AUTO-UPDATED ‡¶∏‡ßá‡¶ï‡¶∂‡¶® ‡¶§‡ßà‡¶∞‡¶ø ‡¶ï‡¶∞‡ßÅ‡¶®
            new_auto_section = f"#AUTO-UPDATED - {channel_name} - {timestamp_with_emoji}\n"
            for keyword, url in channel_urls:
                new_auto_section += f"{url}\n"
            
            if auto_match:
                print(f"‚úÖ Found existing AUTO-UPDATED section, replacing only that")
                # ‡¶∂‡ßÅ‡¶ß‡ßÅ AUTO-UPDATED ‡¶∏‡ßá‡¶ï‡¶∂‡¶® ‡¶∞‡¶ø‡¶™‡ßç‡¶≤‡ßá‡¶∏ ‡¶ï‡¶∞‡ßÅ‡¶®
                old_auto_section = auto_match.group(0)
                updated_rest = rest_of_block.replace(old_auto_section, new_auto_section)
            else:
                print(f"‚úÖ No existing AUTO-UPDATED section, adding new one")
                # EXTINF ‡¶≤‡¶æ‡¶á‡¶®‡ßá‡¶∞ ‡¶™‡¶∞‡ßá‡¶á ‡¶®‡¶§‡ßÅ‡¶® AUTO-UPDATED ‡¶∏‡ßá‡¶ï‡¶∂‡¶® ‡¶Ø‡ßã‡¶ó ‡¶ï‡¶∞‡ßÅ‡¶®
                # ‡¶ï‡¶ø‡¶®‡ßç‡¶§‡ßÅ ‡¶Ü‡¶ó‡ßá‡¶∞ ‡¶∏‡¶¨ ‡¶≤‡¶ø‡¶Ç‡¶ï ‡¶∞‡¶æ‡¶ñ‡ßÅ‡¶®
                lines = rest_of_block.split('\n')
                updated_lines = []
                
                # ‡¶™‡ßç‡¶∞‡¶•‡¶Æ‡ßá EXTINF ‡¶≤‡¶æ‡¶á‡¶® ‡¶∞‡¶æ‡¶ñ‡ßÅ‡¶®
                updated_lines.append(extinf_line.strip())
                
                # ‡¶§‡¶æ‡¶∞‡¶™‡¶∞ ‡¶®‡¶§‡ßÅ‡¶® AUTO-UPDATED ‡¶∏‡ßá‡¶ï‡¶∂‡¶® ‡¶Ø‡ßã‡¶ó ‡¶ï‡¶∞‡ßÅ‡¶®
                updated_lines.append(new_auto_section.strip())
                
                # ‡¶§‡¶æ‡¶∞‡¶™‡¶∞ ‡¶¨‡¶æ‡¶ï‡¶ø ‡¶∏‡¶¨ ‡¶≤‡¶æ‡¶á‡¶® ‡¶Ø‡ßã‡¶ó ‡¶ï‡¶∞‡ßÅ‡¶® (‡¶™‡ßÅ‡¶∞‡¶æ‡¶®‡ßã ‡¶≤‡¶ø‡¶Ç‡¶ï‡¶ó‡ßÅ‡¶≤‡ßã ‡¶∏‡¶π)
                for line in lines:
                    if line.strip():  # ‡¶´‡¶æ‡¶Å‡¶ï‡¶æ ‡¶≤‡¶æ‡¶á‡¶® ‡¶¨‡¶æ‡¶¶
                        updated_lines.append(line)
                
                updated_rest = '\n'.join(updated_lines).replace(extinf_line, '')
            
            # ‡¶™‡ßÅ‡¶∞‡ßã ‡¶¨‡ßç‡¶≤‡¶ï ‡¶Ü‡¶™‡¶°‡ßá‡¶ü ‡¶ï‡¶∞‡ßÅ‡¶®
            updated_block = extinf_line + updated_rest
            updated_content = main_content.replace(full_block, updated_block)
            
            print(f"‚úÖ Successfully updated {channel_name}")
            print(f"   - Added {len(channel_urls)} new URLs in AUTO-UPDATED")
            print(f"   - Preserved ALL original links")
            
            return updated_content
        
        # ‡¶Æ‡ßá‡¶á‡¶® ‡¶™‡ßç‡¶≤‡ßá‡¶≤‡¶ø‡¶∏‡ßç‡¶ü ‡¶≤‡ßã‡¶° ‡¶ï‡¶∞‡ßÅ‡¶®
        with open('main_playlist.m3u', 'r', encoding='utf-8') as f:
            main_content = f.read()
        
        # ‡¶Æ‡ßÇ‡¶≤ ‡¶ï‡¶®‡ßç‡¶ü‡ßá‡¶®‡ßç‡¶ü‡ßá‡¶∞ ‡¶¨‡ßç‡¶Ø‡¶æ‡¶ï‡¶Ü‡¶™ ‡¶®‡¶ø‡¶®
        original_content = main_content
        
        # Check if manual run or scheduled
        import os
        is_manual_run = os.environ.get('GITHUB_EVENT_NAME') == 'workflow_dispatch'
        
        print(f"üìä Run type: {'Manual' if is_manual_run else 'Scheduled'}")
        print(f"üìä Total channels in mapping: {len(CHANNEL_MAPPING)}")
        
        updated_content = main_content
        total_updated = 0
        
        # ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶ü‡¶ø ‡¶Æ‡ßç‡¶Ø‡¶æ‡¶™ ‡¶ï‡¶∞‡¶æ ‡¶ö‡ßç‡¶Ø‡¶æ‡¶®‡ßá‡¶≤‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶Ü‡¶™‡¶°‡ßá‡¶ü ‡¶ï‡¶∞‡ßÅ‡¶®
        for main_channel, search_keywords in CHANNEL_MAPPING.items():
            print(f"\n{'='*50}")
            print(f"üîç Processing: {main_channel}")
            
            # ‡¶™‡ßç‡¶∞‡¶•‡¶Æ‡ßá ‡¶ö‡ßá‡¶ï ‡¶ï‡¶∞‡ßÅ‡¶® ‡¶ö‡ßç‡¶Ø‡¶æ‡¶®‡ßá‡¶≤‡¶ü‡¶ø ‡¶Æ‡ßá‡¶á‡¶® ‡¶™‡ßç‡¶≤‡ßá‡¶≤‡¶ø‡¶∏‡ßç‡¶ü‡ßá ‡¶Ü‡¶õ‡ßá ‡¶ï‡¶ø‡¶®‡¶æ
            if main_channel not in main_content and main_channel.upper() not in main_content.upper():
                print(f"‚ö†Ô∏è Channel '{main_channel}' not found in main playlist, skipping")
                continue
            
            # ‡¶∏‡ßã‡¶∞‡ßç‡¶∏ ‡¶•‡ßá‡¶ï‡ßá URL ‡¶ñ‡ßÅ‡¶Å‡¶ú‡ßÅ‡¶®
            channel_urls = find_channel_urls('source_playlist.m3u', search_keywords)
            
            if channel_urls:
                # ‡¶ö‡ßç‡¶Ø‡¶æ‡¶®‡ßá‡¶≤ ‡¶Ü‡¶™‡¶°‡ßá‡¶ü ‡¶ï‡¶∞‡ßÅ‡¶® (‡¶™‡ßÅ‡¶∞‡¶æ‡¶®‡ßã ‡¶≤‡¶ø‡¶Ç‡¶ï‡¶ó‡ßÅ‡¶≤‡ßã ‡¶∏‡¶Ç‡¶∞‡¶ï‡ßç‡¶∑‡¶£ ‡¶ï‡¶∞‡ßá)
                updated_content = update_channel_safely(updated_content, main_channel, channel_urls)
                total_updated += 1
            else:
                print(f"‚ö†Ô∏è No new URLs found for {main_channel}, keeping existing content")
        
        # ‡¶Ü‡¶™‡¶°‡ßá‡¶ü ‡¶ï‡¶∞‡¶æ ‡¶ï‡¶®‡ßç‡¶ü‡ßá‡¶®‡ßç‡¶ü ‡¶∏‡ßá‡¶≠ ‡¶ï‡¶∞‡ßÅ‡¶®
        with open('sirometv_updated.m3u', 'w', encoding='utf-8') as f:
            f.write(updated_content)
        
        # ‡¶Ü‡¶∏‡¶≤ ‡¶è‡¶¨‡¶Ç ‡¶Ü‡¶™‡¶°‡ßá‡¶ü‡ßá‡¶° ‡¶ï‡¶®‡ßç‡¶ü‡ßá‡¶®‡ßç‡¶ü‡ßá‡¶∞ ‡¶Æ‡¶ß‡ßç‡¶Ø‡ßá ‡¶™‡¶æ‡¶∞‡ßç‡¶•‡¶ï‡ßç‡¶Ø ‡¶ö‡ßá‡¶ï ‡¶ï‡¶∞‡ßÅ‡¶®
        print(f"\n{'='*50}")
        print(f"üéâ Update Summary:")
        print(f"   Run type: {'Manual' if is_manual_run else 'Scheduled'}")
        print(f"   Channels processed: {len(CHANNEL_MAPPING)}")
        print(f"   Channels successfully updated: {total_updated}")
        
        # ‡¶ó‡ßÅ‡¶∞‡ßÅ‡¶§‡ßç‡¶¨‡¶™‡ßÇ‡¶∞‡ßç‡¶£: ‡¶Ü‡¶∏‡¶≤ ‡¶≤‡¶ø‡¶Ç‡¶ï‡¶ó‡ßÅ‡¶≤‡ßã ‡¶†‡¶ø‡¶ï ‡¶Ü‡¶õ‡ßá ‡¶ï‡¶ø‡¶®‡¶æ ‡¶ö‡ßá‡¶ï ‡¶ï‡¶∞‡ßÅ‡¶®
        print(f"\nüîç Verification Check:")
        
        # T Sports ‡¶ö‡ßç‡¶Ø‡¶æ‡¶®‡ßá‡¶≤‡ßá‡¶∞ ‡¶Ü‡¶∏‡¶≤ ‡¶≤‡¶ø‡¶Ç‡¶ï‡¶ó‡ßÅ‡¶≤‡ßã ‡¶ö‡ßá‡¶ï ‡¶ï‡¶∞‡ßÅ‡¶®
        test_channel = "T Sports"
        original_lines = original_content.split('\n')
        updated_lines = updated_content.split('\n')
        
        # ‡¶Ü‡¶∏‡¶≤ ‡¶ï‡¶®‡ßç‡¶ü‡ßá‡¶®‡ßç‡¶ü‡ßá T Sports ‡¶è‡¶∞ ‡¶≤‡¶ø‡¶Ç‡¶ï‡¶ó‡ßÅ‡¶≤‡ßã ‡¶ñ‡ßÅ‡¶Å‡¶ú‡ßÅ‡¶®
        print(f"   Checking {test_channel} original links:")
        in_t_sports = False
        original_link_count = 0
        
        for i, line in enumerate(original_lines):
            if test_channel in line and line.startswith('#EXTINF:'):
                in_t_sports = True
                continue
            if in_t_sports and line.startswith('#EXTINF:'):
                break
            if in_t_sports and (line.startswith('http://') or line.startswith('https://')):
                original_link_count += 1
                print(f"     ‚úì Original link {original_link_count}: {line[:60]}...")
        
        # ‡¶Ü‡¶™‡¶°‡ßá‡¶ü‡ßá‡¶° ‡¶ï‡¶®‡ßç‡¶ü‡ßá‡¶®‡ßç‡¶ü‡ßá T Sports ‡¶è‡¶∞ ‡¶≤‡¶ø‡¶Ç‡¶ï‡¶ó‡ßÅ‡¶≤‡ßã ‡¶ñ‡ßÅ‡¶Å‡¶ú‡ßÅ‡¶®
        print(f"\n   Checking {test_channel} updated links:")
        in_t_sports = False
        updated_link_count = 0
        
        for i, line in enumerate(updated_lines):
            if test_channel in line and line.startswith('#EXTINF:'):
                in_t_sports = True
                continue
            if in_t_sports and line.startswith('#EXTINF:'):
                break
            if in_t_sports and (line.startswith('http://') or line.startswith('https://')):
                updated_link_count += 1
                print(f"     ‚úì Updated link {updated_link_count}: {line[:60]}...")
        
        print(f"\n   Result: Original had {original_link_count} links, Updated has {updated_link_count} links")
        
        if original_link_count <= updated_link_count:
            print(f"   ‚úÖ SUCCESS: All original links preserved!")
        else:
            print(f"   ‚ö†Ô∏è WARNING: Some original links might be missing")
        
        # ‡¶≤‡¶æ‡¶á‡¶® ‡¶∏‡¶Ç‡¶ñ‡ßç‡¶Ø‡¶æ ‡¶§‡ßÅ‡¶≤‡¶®‡¶æ
        print(f"\nüìä Line Count Comparison:")
        print(f"   Original: {len(original_lines)} lines")
        print(f"   Updated:  {len(updated_lines)} lines")
        print(f"   Difference: {len(updated_lines) - len(original_lines)} lines")
        
        EOF
        
    - name: Verify and replace playlist
      run: |
        echo "üîç Verifying updated playlist..."
        
        if [ ! -f "sirometv_updated.m3u" ] || [ ! -s "sirometv_updated.m3u" ]; then
          echo "‚ùå ERROR: Updated playlist is missing or empty!"
          exit 1
        fi
        
        # ‡¶Æ‡ßÇ‡¶≤ ‡¶è‡¶¨‡¶Ç ‡¶Ü‡¶™‡¶°‡ßá‡¶ü‡ßá‡¶° ‡¶´‡¶æ‡¶á‡¶≤‡ßá‡¶∞ ‡¶≤‡¶æ‡¶á‡¶® ‡¶∏‡¶Ç‡¶ñ‡ßç‡¶Ø‡¶æ ‡¶§‡ßÅ‡¶≤‡¶®‡¶æ
        echo "üìä Comparing file sizes:"
        ORIGINAL_SIZE=$(wc -l < main_playlist.m3u)
        UPDATED_SIZE=$(wc -l < sirometv_updated.m3u)
        echo "   Original: $ORIGINAL_SIZE lines"
        echo "   Updated:  $UPDATED_SIZE lines"
        echo "   Difference: $((UPDATED_SIZE - ORIGINAL_SIZE)) lines"
        
        # Check if all original links are preserved
        echo ""
        echo "üîç Checking if original links are preserved:"
        
        # T Sports ‡¶è‡¶∞ ‡¶Ü‡¶∏‡¶≤ ‡¶≤‡¶ø‡¶Ç‡¶ï‡¶ó‡ßÅ‡¶≤‡ßã ‡¶ö‡ßá‡¶ï ‡¶ï‡¶∞‡ßÅ‡¶®
        echo "   T Sports original links count in original file:"
        grep -A 10 "T Sports" main_playlist.m3u | grep -c "^http" || true
        
        echo "   T Sports links count in updated file:"
        grep -A 20 "T Sports" sirometv_updated.m3u | grep -c "^http" || true
        
        # Show sample of T Sports section to verify
        echo ""
        echo "üîç T Sports section in updated file (first 25 lines):"
        grep -n -A 25 "T Sports" sirometv_updated.m3u | head -30 || echo "No T Sports found"
        
        # Count total channels in both files
        echo ""
        echo "üìä Total channel count:"
        ORIGINAL_CHANNELS=$(grep -c "^#EXTINF:" main_playlist.m3u || true)
        UPDATED_CHANNELS=$(grep -c "^#EXTINF:" sirometv_updated.m3u || true)
        echo "   Original channels: $ORIGINAL_CHANNELS"
        echo "   Updated channels: $UPDATED_CHANNELS"
        
        if [ "$ORIGINAL_CHANNELS" -eq "$UPDATED_CHANNELS" ]; then
          echo "   ‚úÖ All channels preserved!"
        else
          echo "   ‚ö†Ô∏è Channel count mismatch!"
        fi
        
        mv sirometv_updated.m3u sirometv.m3u
        
    - name: Commit and push changes
      run: |
        echo "üíæ Saving changes to repository..."
        
        git config user.name "github-actions[bot]"
        git config user.email "github-actions[bot]@users.noreply.github.com"
        git add sirometv.m3u
        
        if git diff --staged --quiet; then
          echo "‚úÖ No changes detected - playlist is up to date"
        else
          # ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ‡¶¶‡ßá‡¶∂‡ßá‡¶∞ ‡¶∏‡¶Æ‡ßü ‡¶®‡ßá‡¶ì‡ßü‡¶æ (BD Time format)
          BANGLADESH_TIME=$(TZ='Asia/Dhaka' date +'%Y-%m-%d %I:%M:%S%p BD Time')
          
          # Check if manual or scheduled run
          if [ "${{ github.event_name }}" == "workflow_dispatch" ]; then
            git commit -m "üîÑ Manual Update: Preserved All Original Links - $BANGLADESH_TIME"
          else
            git commit -m "üîÑ Scheduled Update: Preserved All Original Links - $BANGLADESH_TIME"
          fi
          git push
          echo "üéâ Successfully updated while preserving ALL original links!"
        fi
        
    - name: Cleanup
      run: |
        rm -f main_playlist.m3u source_playlist.m3u
        echo "‚úÖ Cleanup completed!"
