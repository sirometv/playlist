name: Combined Playlist Skipper üü¢

on:
  schedule:
    - cron: '*/5 * * * *'
  workflow_dispatch:

permissions:
  contents: write

jobs:
  update-playlists:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
        fetch-depth: 0
        
    - name: Download all playlists
      run: |
        echo "üì• Downloading all required playlists..."
        
        # ‡¶™‡ßç‡¶∞‡¶•‡¶Æ‡ßá ‡¶Æ‡ßá‡¶á‡¶® ‡¶™‡ßç‡¶≤‡ßá‡¶≤‡¶ø‡¶∏‡ßç‡¶ü ‡¶ñ‡¶æ‡¶≤‡¶ø ‡¶´‡¶æ‡¶á‡¶≤‡ßá ‡¶∞‡ßÇ‡¶™‡¶æ‡¶®‡ßç‡¶§‡¶∞
        echo "" > main_playlist.m3u
        
        # Source playlists
        curl -s -L -o source_playlist.m3u "https://raw.githubusercontent.com/sirometv/playlist/gh-pages/sirometv.m3u"
        curl -s -L -o ayna_source.m3u "https://raw.githubusercontent.com/sirometv/playlist/main/Ayna.m3u"
        curl -s -L -o fancode_source.m3u "https://raw.githubusercontent.com/abusaeeidx/Mrgify-BDIX-IPTV/main/playlist.m3u"
        
        # Verify downloads
        for file in source_playlist.m3u ayna_source.m3u fancode_source.m3u; do
          if [ ! -f "$file" ] || [ ! -s "$file" ]; then
            echo "‚ùå ERROR: $file download failed!"
            exit 1
          fi
          LINES=$(wc -l < "$file")
          echo "‚úÖ $file downloaded - $LINES lines"
        done
        
    - name: Copy from source to main playlist
      run: |
        echo "üìã Copying from source playlist to main playlist..."
        
        # ‡¶∏‡ßã‡¶∞‡ßç‡¶∏ ‡¶™‡ßç‡¶≤‡ßá‡¶≤‡¶ø‡¶∏‡ßç‡¶ü ‡¶•‡ßá‡¶ï‡ßá ‡¶Æ‡ßá‡¶á‡¶® ‡¶™‡ßç‡¶≤‡ßá‡¶≤‡¶ø‡¶∏‡ßç‡¶ü‡ßá ‡¶ï‡¶™‡¶ø ‡¶ï‡¶∞‡ßÅ‡¶®
        cp source_playlist.m3u main_playlist.m3u
        
        # Verify copy
        if [ ! -s "main_playlist.m3u" ]; then
          echo "‚ùå ERROR: main_playlist.m3u is empty after copy!"
          exit 1
        fi
        
        LINES=$(wc -l < "main_playlist.m3u")
        echo "‚úÖ Main playlist now has $LINES lines"
        
    - name: Backup original playlist
      run: |
        cp main_playlist.m3u main_playlist_backup.m3u
        echo "üì¶ Original playlist backed up"
        
    - name: Update All Channel üîÑ
      run: |
        echo "üîÑ Starting All Channel üîÑ update..."
        
        python3 - << 'EOF'
        import re
        from datetime import datetime
        import pytz
        import os
        
        # ‡¶ö‡ßç‡¶Ø‡¶æ‡¶®‡ßá‡¶≤ ‡¶Æ‡ßç‡¶Ø‡¶æ‡¶™‡¶ø‡¶Ç - ‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶™‡ßç‡¶∞‡¶•‡¶Æ ‡¶™‡ßç‡¶≤‡ßá‡¶≤‡¶ø‡¶∏‡ßç‡¶ü‡ßá‡¶∞ ‡¶®‡¶æ‡¶Æ : ‡¶∏‡ßá‡¶ï‡ßá‡¶®‡ßç‡¶° ‡¶™‡ßç‡¶≤‡ßá‡¶≤‡¶ø‡¶∏‡ßç‡¶ü‡ßá ‡¶ñ‡ßÅ‡¶Å‡¶ú‡¶¨‡ßá ‡¶è‡¶Æ‡¶® keywords
        CHANNEL_MAPPING = {
            "BTV National": ["BTV NATIONAL HD", "BTV World"],
            "BTV CTG": ["BTV CTG"],
            "Somoy TV": ["Somoy News TV", "Somoy TV"],
            "Jamuna TV": ["Jamuna TV","JAMUNA TV"],
            "Ekushey TV": ["Ekushey TV"],
            "NTV BD": ["NTV"],
            "NTV-Europe": ["NTV Europe"],
            "Channel 24": ["Channel 24"],
            "Deen TV": ["Deen TV"],
            "SATV": ["SA TV"],
            "GTV": ["Gazi TV"],
            "T Sports": ["T Sports HD", "A Sports", "PTV Sports"],
            "Channel 9": ["Channel 9"],
            "Channel I": ["Channel I"],
            "Bangla Vision": ["Bangla Vision"],
            "News 24": ["News 24 BD"], 
            "Boishakhi TV": ["Boishakhi TV"],
            "Bijoy TV": ["Bijoy TV"],
            "ATN Bangla": ["ATN Bangla"],
            "ATN-Bangla News": ["ATN News"],
            "DBC News": ["DBC News"],
            "Independent TV": ["Independent TV"],
            "Bangla TV": ["Bangla TV"],
            "Desh TV": ["Desh TV"],
            "RTV": ["RTV"],
            "My TV": ["My TV"],
            "Duronto": ["Duronto TV"],
            "Deepto TV": ["Deepto TV"],
            "Mohona TV": ["Mohona TV"],
            "Ananda TV": ["Ananda TV"],
            "Asian TV": ["Asian TV"],
            "Gaan Bangla": ["Gaan Bangla", "GAAN BANGLA", "gaan bangla", "Gaan", "GAAN"],
            "Channel 5 TV": ["Channel 5 TV"],
            "Music Bangla": ["Music Bangla"],
            "Ekattor TV": ["Ekattor TV"],
            "Nagorik TV": ["Nagorik TV"],
            "Ekhon TV": ["Ekhon TV"],
            "Peace TV Bangla": ["Peace TV Bangla HD"],
            "Islam Bangla": ["Islam Bangla"],
            "Iqra TV ": ["Iqra Bangla"],
            "Madani TV": ["Madani TV"],
            "News21 TV": ["News21 TV"],
            "Bangla 21": ["Bangla 21"],
            "Movie Bangla": ["Movie Bangla"],
            "Matri Bhumi": ["Matri Bhumi"],
            "Magic Bangla": ["Magic Bangla"],
            "Alpona TV": ["Alpona TV"],
            "Channel A1": ["Channel A1"],
            "Shadin Bangla": ["Shadin Bangla"],
            "Channel S UK": ["Channel S UK HD"],
            "Nandan TV": ["Nandan TV"],
            "Global TV": ["Global TV"],
            "Deshi TV": ["Deshi TV", "Deshi TV (720p)"],
            "Falguni TV": ["Falguni TV"],
            "Channel S BD": ["Channel S BD","Channel S HD"],
            "Rajdhani TV": ["Rajdhani TV"],
            "Rongeen TV": ["Rongeen TV"],
            "Sonic Bangla": ["Sonic Bangla"],
            "Discovery Kids": ["Discovery Kids"],
            "NAN TV": ["NAN TV"],
            "Star Jalsha": ["Star Jalsha HD", "Star Jalsha"],
            "Star-Jalsha Movies": ["Star Jalsha Movies HD"],
            "Zee Bangla": ["Zee Bangla International", "Zee Bangla"],
            "Zee-Bangla Cinema": ["Zee Bangla Cinema"],
            "Colors Bengali": ["colors bangla"],
            "Sangeet Bangla": ["Sangeet Bangla"],
            "Sony Aaat": ["Sony Aaat"],
            "Enter 10 Bangla": ["Enter 10 Bangla"],
            "Zee 24 Ghanta": ["Zee 24 Ghanta"],
        }
        
        def get_bangladesh_time():
            """‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ‡¶¶‡ßá‡¶∂‡ßá‡¶∞ ‡¶¨‡¶∞‡ßç‡¶§‡¶Æ‡¶æ‡¶® ‡¶∏‡¶Æ‡¶Ø‡¶º ‡¶∞‡¶ø‡¶ü‡¶æ‡¶∞‡ßç‡¶® ‡¶ï‡¶∞‡ßá"""
            bangladesh_tz = pytz.timezone('Asia/Dhaka')
            now = datetime.now(bangladesh_tz)
            return now.strftime("%Y-%m-%d %I:%M:%S%p BD Time")
        
        def extract_channel_links_from_playlist(file_path, channel_name, keywords):
            """‡¶™‡ßç‡¶≤‡ßá‡¶≤‡¶ø‡¶∏‡ßç‡¶ü ‡¶•‡ßá‡¶ï‡ßá ‡¶®‡¶ø‡¶∞‡ßç‡¶¶‡¶ø‡¶∑‡ßç‡¶ü ‡¶ö‡ßç‡¶Ø‡¶æ‡¶®‡ßá‡¶≤‡ßá‡¶∞ ‡¶∏‡¶Æ‡¶∏‡ßç‡¶§ ‡¶≤‡¶ø‡¶Ç‡¶ï ‡¶∏‡¶Ç‡¶ó‡ßç‡¶∞‡¶π ‡¶ï‡¶∞‡ßá"""
            channel_links = []
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # ‡¶™‡ßç‡¶∞‡¶•‡¶Æ‡ßá channel_name ‡¶¶‡¶ø‡ßü‡ßá ‡¶ñ‡ßã‡¶Å‡¶ú‡¶æ
            patterns_to_try = [channel_name] + keywords
            
            for pattern_keyword in patterns_to_try:
                # EXTINF ‡¶≤‡¶æ‡¶á‡¶® ‡¶Ø‡ßá‡¶ñ‡¶æ‡¶®‡ßá channel_name ‡¶¨‡¶æ keyword ‡¶Ü‡¶õ‡ßá
                pattern = r'(#EXTINF:[^\n]*{}[^\n]*\n)((?:http[^\n]*\n)+)'.format(re.escape(pattern_keyword))
                matches = re.finditer(pattern, content, re.IGNORECASE)
                
                for match in matches:
                    url_block = match.group(2)
                    # URL ‡¶¨‡ßç‡¶≤‡¶ï ‡¶•‡ßá‡¶ï‡ßá ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶ü‡¶ø ‡¶≤‡¶ø‡¶Ç‡¶ï ‡¶Ü‡¶≤‡¶æ‡¶¶‡¶æ ‡¶ï‡¶∞‡¶æ
                    urls = url_block.strip().split('\n')
                    for url in urls:
                        if url.startswith('http'):
                            channel_links.append(url.strip())
                    # ‡¶è‡¶ï‡¶¨‡¶æ‡¶∞ ‡¶™‡ßá‡ßü‡ßá ‡¶ó‡ßá‡¶≤‡ßá ‡¶¨‡ßá‡¶∞ ‡¶π‡ßü‡ßá ‡¶Ø‡¶æ‡¶ì‡ßü‡¶æ
                    break
                if channel_links:  # ‡¶Ø‡¶¶‡¶ø ‡¶≤‡¶ø‡¶Ç‡¶ï ‡¶™‡¶æ‡¶ì‡ßü‡¶æ ‡¶Ø‡¶æ‡ßü
                    break
            
            return list(set(channel_links))  # ‡¶°‡ßÅ‡¶™‡ßç‡¶≤‡¶ø‡¶ï‡ßá‡¶ü ‡¶Æ‡ßÅ‡¶õ‡ßá ‡¶´‡ßá‡¶≤‡¶æ
        
        def find_all_channel_urls(source_file, keywords):
            """‡¶∏‡ßã‡¶∞‡ßç‡¶∏ ‡¶™‡ßç‡¶≤‡ßá‡¶≤‡¶ø‡¶∏‡ßç‡¶ü ‡¶•‡ßá‡¶ï‡ßá ‡¶ö‡ßç‡¶Ø‡¶æ‡¶®‡ßá‡¶≤‡ßá‡¶∞ ‡¶∏‡¶Æ‡¶∏‡ßç‡¶§ URL ‡¶ñ‡ßÅ‡¶Å‡¶ú‡ßá ‡¶¨‡ßá‡¶∞ ‡¶ï‡¶∞‡ßá"""
            all_urls = []
            
            with open(source_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # ‡¶∏‡¶¨ keywords ‡¶è‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶ö‡ßá‡¶∑‡ßç‡¶ü‡¶æ ‡¶ï‡¶∞‡ßÅ‡¶®
            for keyword in keywords:
                pattern = r'#EXTINF:[^\n]*{}[^\n]*\n((?:http[^\n]*\n)+)'.format(re.escape(keyword))
                match = re.search(pattern, content, re.IGNORECASE)
                
                if match:
                    url_block = match.group(1)
                    # URL ‡¶¨‡ßç‡¶≤‡¶ï ‡¶•‡ßá‡¶ï‡ßá ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶ü‡¶ø ‡¶≤‡¶ø‡¶Ç‡¶ï ‡¶Ü‡¶≤‡¶æ‡¶¶‡¶æ ‡¶ï‡¶∞‡¶æ
                    urls = url_block.strip().split('\n')
                    for url in urls:
                        if url.startswith('http'):
                            all_urls.append(url.strip())
                    # ‡¶è‡¶ï‡¶¨‡¶æ‡¶∞ ‡¶™‡ßá‡ßü‡ßá ‡¶ó‡ßá‡¶≤‡ßá ‡¶¨‡ßá‡¶∞ ‡¶π‡ßü‡ßá ‡¶Ø‡¶æ‡¶ì‡ßü‡¶æ
                    break
            
            return list(set(all_urls))  # ‡¶°‡ßÅ‡¶™‡ßç‡¶≤‡¶ø‡¶ï‡ßá‡¶ü ‡¶Æ‡ßÅ‡¶õ‡ßá ‡¶´‡ßá‡¶≤‡¶æ
        
        def update_channel_with_multiple_links(main_content, channel_name, source_links, ayna_links, is_manual_run):
            """‡¶Æ‡ßá‡¶á‡¶® ‡¶™‡ßç‡¶≤‡ßá‡¶≤‡¶ø‡¶∏‡ßç‡¶ü‡ßá ‡¶®‡¶ø‡¶∞‡ßç‡¶¶‡¶ø‡¶∑‡ßç‡¶ü ‡¶ö‡ßç‡¶Ø‡¶æ‡¶®‡ßá‡¶≤‡¶ï‡ßá ‡¶Ü‡¶™‡¶°‡ßá‡¶ü ‡¶ï‡¶∞‡ßá (‡¶è‡¶ï‡¶æ‡¶ß‡¶ø‡¶ï ‡¶≤‡¶ø‡¶Ç‡¶ï ‡¶∏‡¶π)"""
            timestamp = get_bangladesh_time()
            
            # Pattern: #EXTINF ‡¶≤‡¶æ‡¶á‡¶® ‡¶Ø‡ßá‡¶ñ‡¶æ‡¶®‡ßá channel_name ‡¶Ü‡¶õ‡ßá
            pattern_extinf = r'(#EXTINF:-1[^\n]*{}[^\n]*\n)'.format(re.escape(channel_name))
            
            match = re.search(pattern_extinf, main_content, re.IGNORECASE)
            if not match:
                print(f"‚ùå {channel_name} not found in main playlist")
                return main_content
            
            # ‡¶®‡¶§‡ßÅ‡¶® ‡¶≤‡¶ø‡¶Ç‡¶ï‡¶ó‡ßÅ‡¶≤‡ßã (‡¶Ø‡ßá‡¶ó‡ßÅ‡¶≤‡ßã source_playlist ‡¶è ‡¶®‡ßá‡¶á)
            new_links = []
            skipped_links = []
            
            for ayna_link in ayna_links:
                if ayna_link in source_links:
                    skipped_links.append(ayna_link)
                else:
                    new_links.append(ayna_link)
            
            # ‡¶Ø‡¶¶‡¶ø ‡¶ï‡ßã‡¶®‡ßã ‡¶≤‡¶ø‡¶Ç‡¶ï ‡¶∏‡ßç‡¶ï‡¶ø‡¶™ ‡¶π‡ßü
            has_skipped = len(skipped_links) > 0
            
            # ‡¶ö‡ßç‡¶Ø‡¶æ‡¶®‡ßá‡¶≤‡ßá‡¶∞ ‡¶∏‡¶Æ‡ßç‡¶™‡ßÇ‡¶∞‡ßç‡¶£ ‡¶¨‡ßç‡¶≤‡¶ï ‡¶ñ‡ßÅ‡¶Å‡¶ú‡ßá ‡¶¨‡ßá‡¶∞ ‡¶ï‡¶∞‡¶æ
            # ‡¶™‡ßç‡¶Ø‡¶æ‡¶ü‡¶æ‡¶∞‡ßç‡¶®: EXTINF ‡¶≤‡¶æ‡¶á‡¶® + AUTO-UPDATED ‡¶≤‡¶æ‡¶á‡¶® (‡¶ê‡¶ö‡ßç‡¶õ‡¶ø‡¶ï) + ‡¶∏‡¶Æ‡¶∏‡ßç‡¶§ URL ‡¶≤‡¶æ‡¶á‡¶®
            channel_pattern = r'(#EXTINF:-1[^\n]*{}[^\n]*\n)((?:#AUTO-UPDATED[^\n]*\n)?)((?:http[^\n]*\n)*)'.format(re.escape(channel_name))
            channel_match = re.search(channel_pattern, main_content, re.IGNORECASE)
            
            if not channel_match:
                return main_content
            
            extinf_line = channel_match.group(1)
            auto_line = channel_match.group(2) if channel_match.group(2) else ""
            existing_urls_block = channel_match.group(3)
            
            # ‡¶®‡¶§‡ßÅ‡¶® ‡¶¨‡ßç‡¶≤‡¶ï ‡¶§‡ßà‡¶∞‡¶ø
            new_block = extinf_line
            
            if has_skipped:
                # ‡¶∏‡ßç‡¶ï‡¶ø‡¶™ ‡¶Æ‡ßá‡¶∏‡ßá‡¶ú ‡¶Ø‡ßã‡¶ó ‡¶ï‡¶∞‡¶æ
                skip_message = f"#AUTO-UPDATED - {channel_name} ‚õî SKIPPED ‚õî - {timestamp} üü° - üîÑ - üî¥\n"
                new_block += skip_message
                print(f"‚õî Skipped {len(skipped_links)} links for {channel_name} - already in source playlist")
            elif len(new_links) > 0:
                # ‡¶®‡¶§‡ßÅ‡¶® ‡¶Ü‡¶™‡¶°‡ßá‡¶ü ‡¶Æ‡ßá‡¶∏‡ßá‡¶ú ‡¶Ø‡ßã‡¶ó ‡¶ï‡¶∞‡¶æ
                update_message = f"#AUTO-UPDATED - {channel_name} ‚úÖ- {timestamp} üü° - üîÑ - üî¥\n"
                new_block += update_message
                print(f"‚úÖ Added {len(new_links)} new links for {channel_name}")
            
            # ‡¶®‡¶§‡ßÅ‡¶® ‡¶≤‡¶ø‡¶Ç‡¶ï‡¶ó‡ßÅ‡¶≤‡ßã ‡¶Ø‡ßã‡¶ó ‡¶ï‡¶∞‡¶æ (Ayna ‡¶•‡ßá‡¶ï‡ßá ‡¶®‡¶§‡ßÅ‡¶® ‡¶≤‡¶ø‡¶Ç‡¶ï‡¶ó‡ßÅ‡¶≤‡¶ø ‡¶™‡ßç‡¶∞‡¶•‡¶Æ‡ßá/‡¶â‡¶™‡¶∞‡ßá)
            for new_link in new_links:
                new_block += new_link + "\n"
            
            # ‡¶¨‡¶ø‡¶¶‡ßç‡¶Ø‡¶Æ‡¶æ‡¶® URL ‡¶¨‡ßç‡¶≤‡¶ï ‡¶Ø‡ßã‡¶ó ‡¶ï‡¶∞‡¶æ (gh-pages/sirometv.m3u ‡¶è‡¶∞ ‡¶≤‡¶ø‡¶Ç‡¶ï‡¶ó‡ßÅ‡¶≤‡¶ø ‡¶™‡¶∞‡ßá/‡¶®‡¶ø‡¶ö‡ßá)
            new_block += existing_urls_block
            
            # ‡¶Æ‡ßá‡¶á‡¶® ‡¶ï‡¶®‡ßç‡¶ü‡ßá‡¶®‡ßç‡¶ü‡ßá ‡¶∞‡¶ø‡¶™‡ßç‡¶≤‡ßá‡¶∏ ‡¶ï‡¶∞‡¶æ
            updated_content = main_content.replace(channel_match.group(0), new_block)
            
            return updated_content
        
        # ‡¶Æ‡ßá‡¶á‡¶® ‡¶™‡ßç‡¶≤‡ßá‡¶≤‡¶ø‡¶∏‡ßç‡¶ü ‡¶≤‡ßã‡¶° ‡¶ï‡¶∞‡ßÅ‡¶®
        with open('main_playlist.m3u', 'r', encoding='utf-8') as f:
            main_content = f.read()
        
        # Check if manual run or scheduled
        is_manual_run = os.environ.get('GITHUB_EVENT_NAME') == 'workflow_dispatch'
        
        updated_content = main_content
        updated_channels = 0
        skipped_channels = 0
        total_new_links_added = 0
        total_skipped_links = 0
        
        # ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶ü‡¶ø ‡¶ö‡ßç‡¶Ø‡¶æ‡¶®‡ßá‡¶≤‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶Ü‡¶™‡¶°‡ßá‡¶ü ‡¶ï‡¶∞‡ßÅ‡¶®
        for main_channel, search_keywords in CHANNEL_MAPPING.items():
            print(f"\nüîç Processing: {main_channel}")
            print(f"   Run type: {'Manual' if is_manual_run else 'Scheduled'}")
            
            # Ayna playlist ‡¶•‡ßá‡¶ï‡ßá ‡¶ö‡ßç‡¶Ø‡¶æ‡¶®‡ßá‡¶≤‡ßá‡¶∞ ‡¶∏‡¶Æ‡¶∏‡ßç‡¶§ ‡¶≤‡¶ø‡¶Ç‡¶ï ‡¶∏‡¶Ç‡¶ó‡ßç‡¶∞‡¶π ‡¶ï‡¶∞‡ßÅ‡¶®
            ayna_links = find_all_channel_urls('ayna_source.m3u', search_keywords)
            
            if ayna_links:
                print(f"   Found {len(ayna_links)} links in Ayna playlist")
                
                # Source playlist ‡¶•‡ßá‡¶ï‡ßá ‡¶ö‡ßç‡¶Ø‡¶æ‡¶®‡ßá‡¶≤‡ßá‡¶∞ ‡¶≤‡¶ø‡¶Ç‡¶ï‡¶ó‡ßÅ‡¶≤‡ßã ‡¶∏‡¶Ç‡¶ó‡ßç‡¶∞‡¶π ‡¶ï‡¶∞‡ßÅ‡¶®
                source_links = extract_channel_links_from_playlist('source_playlist.m3u', main_channel, search_keywords)
                print(f"   Found {len(source_links)} links in source playlist")
                
                # ‡¶ö‡ßá‡¶ï ‡¶ï‡¶∞‡ßÅ‡¶® ‡¶ï‡ßã‡¶® ‡¶≤‡¶ø‡¶Ç‡¶ï‡¶ó‡ßÅ‡¶≤‡ßã ‡¶∏‡ßç‡¶ï‡¶ø‡¶™ ‡¶π‡¶¨‡ßá ‡¶è‡¶¨‡¶Ç ‡¶ï‡ßã‡¶®‡¶ó‡ßÅ‡¶≤‡ßã ‡¶®‡¶§‡ßÅ‡¶®
                skipped_links = []
                new_links = []
                
                for ayna_link in ayna_links:
                    if ayna_link in source_links:
                        skipped_links.append(ayna_link)
                    else:
                        new_links.append(ayna_link)
                
                if len(skipped_links) > 0 or len(new_links) > 0:
                    # ‡¶ö‡ßç‡¶Ø‡¶æ‡¶®‡ßá‡¶≤ ‡¶Ü‡¶™‡¶°‡ßá‡¶ü ‡¶ï‡¶∞‡ßÅ‡¶®
                    updated_content = update_channel_with_multiple_links(
                        updated_content, 
                        main_channel, 
                        source_links, 
                        ayna_links, 
                        is_manual_run
                    )
                    
                    if len(skipped_links) > 0:
                        skipped_channels += 1
                        total_skipped_links += len(skipped_links)
                    
                    if len(new_links) > 0:
                        updated_channels += 1
                        total_new_links_added += len(new_links)
                    
                    print(f"   Results: {len(new_links)} new links, {len(skipped_links)} skipped links")
                else:
                    print(f"‚ö†Ô∏è No changes needed for {main_channel}")
            else:
                print(f"‚ùå No links found for {main_channel} in Ayna playlist")
        
        # ‡¶Ü‡¶™‡¶°‡ßá‡¶ü ‡¶ï‡¶∞‡¶æ ‡¶ï‡¶®‡ßç‡¶ü‡ßá‡¶®‡ßç‡¶ü temporary ‡¶´‡¶æ‡¶á‡¶≤‡ßá ‡¶∏‡ßá‡¶≠ ‡¶ï‡¶∞‡ßÅ‡¶®
        with open('temp_after_all_channel.m3u', 'w', encoding='utf-8') as f:
            f.write(updated_content)
        
        print(f"\nüéâ All Channel üîÑ Update Summary:")
        print(f"   Run type: {'Manual' if is_manual_run else 'Scheduled'}")
        print(f"   Total channels processed: {len(CHANNEL_MAPPING)}")
        print(f"   Channels with new links: {updated_channels}")
        print(f"   Channels with skipped links: {skipped_channels}")
        print(f"   Total new links added: {total_new_links_added}")
        print(f"   Total links skipped: {total_skipped_links}")
        
        EOF
        
        echo "‚úÖ All Channel üîÑ update completed!"
        
    - name: Update Live Fancode üîÑ
      run: |
        echo "üîÑ Starting Live Fancode üîÑ update..."
        
        python3 - << 'EOF'
        import re
        from datetime import datetime
        import pytz
        
        # ‚öôÔ∏è CONFIGURATION
        TARGET_LINE_NUMBER = 25  # ‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶á‡¶ö‡ßç‡¶õ‡¶æ‡¶Æ‡¶§ ‡¶≤‡¶æ‡¶á‡¶® ‡¶®‡¶Æ‡ßç‡¶¨‡¶∞ ‡¶™‡¶∞‡¶ø‡¶¨‡¶∞‡ßç‡¶§‡¶® ‡¶ï‡¶∞‡ßÅ‡¶®
        
        # ‡¶ó‡ßç‡¶∞‡ßÅ‡¶™ ‡¶ü‡¶æ‡¶á‡¶ü‡ßá‡¶≤‡ßá‡¶∞ ‡¶≤‡¶ø‡¶∏‡ßç‡¶ü
        TARGET_GROUP_TITLES = [
            "Live Event",
            # "Cricket",    # uncomment ‡¶ï‡¶∞‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡ßá‡¶® ‡¶Ø‡¶¶‡¶ø ‡¶™‡ßç‡¶∞‡ßü‡ßã‡¶ú‡¶® ‡¶π‡ßü
            # "Akash Go",    # uncomment ‡¶ï‡¶∞‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡ßá‡¶® ‡¶Ø‡¶¶‡¶ø ‡¶™‡ßç‡¶∞‡ßü‡ßã‡¶ú‡¶® ‡¶π‡ßü
            # "Football",    # uncomment ‡¶ï‡¶∞‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡ßá‡¶® ‡¶Ø‡¶¶‡¶ø ‡¶™‡ßç‡¶∞‡ßü‡ßã‡¶ú‡¶® ‡¶π‡ßü
            # "Sports",      # uncomment ‡¶ï‡¶∞‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡ßá‡¶® ‡¶Ø‡¶¶‡¶ø ‡¶™‡ßç‡¶∞‡ßü‡ßã‡¶ú‡¶® ‡¶π‡ßü
            # "Movies",      # uncomment ‡¶ï‡¶∞‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡ßá‡¶® ‡¶Ø‡¶¶‡¶ø ‡¶™‡ßç‡¶∞‡ßü‡ßã‡¶ú‡¶® ‡¶π‡ßü
        ]
        
        def get_bangladesh_time():
            """‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ‡¶¶‡ßá‡¶∂‡ßá‡¶∞ ‡¶¨‡¶∞‡ßç‡¶§‡¶Æ‡¶æ‡¶® ‡¶∏‡¶Æ‡¶Ø‡¶º ‡¶∞‡¶ø‡¶ü‡¶æ‡¶∞‡ßç‡¶® ‡¶ï‡¶∞‡ßá"""
            bangladesh_tz = pytz.timezone('Asia/Dhaka')
            now = datetime.now(bangladesh_tz)
            return now.strftime("%Y-%m-%d %I:%M:%S%p BD Time")
        
        def get_channel_name_strategy(group_title, extinf_line):
            """‡¶ó‡ßç‡¶∞‡ßÅ‡¶™ ‡¶Ö‡¶®‡ßÅ‡¶Ø‡¶æ‡ßü‡ßÄ ‡¶ö‡ßç‡¶Ø‡¶æ‡¶®‡ßá‡¶≤ ‡¶®‡¶æ‡¶Æ‡ßá‡¶∞ strategy ‡¶®‡¶ø‡¶∞‡ßç‡¶ß‡¶æ‡¶∞‡¶£ ‡¶ï‡¶∞‡ßá"""
            # ‡¶ö‡ßç‡¶Ø‡¶æ‡¶®‡ßá‡¶≤ ‡¶®‡¶æ‡¶Æ extract ‡¶ï‡¶∞‡¶æ
            channel_name_match = re.search(r',([^,\n]+)$', extinf_line)
            original_name = channel_name_match.group(1).strip() if channel_name_match else ""
            
            if group_title == "Live Event":
                return "üî¥Live Nowüî¥"  # Live Event ‡¶ó‡ßç‡¶∞‡ßÅ‡¶™‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶°‡¶ø‡¶´‡¶≤‡ßç‡¶ü ‡¶®‡¶æ‡¶Æ
            elif group_title == "Sports":
                return "Sports Live"  # Sports ‡¶ó‡ßç‡¶∞‡ßÅ‡¶™‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶°‡¶ø‡¶´‡¶≤‡ßç‡¶ü ‡¶®‡¶æ‡¶Æ
            elif group_title == "Akash Go":
                return original_name  # Akash Go ‡¶ó‡ßç‡¶∞‡ßÅ‡¶™‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶Ü‡¶∏‡¶≤ ‡¶®‡¶æ‡¶Æ ‡¶∞‡¶æ‡¶ñ‡¶¨‡ßá
            else:
                return original_name  # ‡¶Ö‡¶®‡ßç‡¶Ø‡¶æ‡¶®‡ßç‡¶Ø ‡¶ó‡ßç‡¶∞‡ßÅ‡¶™‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶Ü‡¶∏‡¶≤ ‡¶®‡¶æ‡¶Æ
        
        def extract_group_channels(source_file, group_title):
            """‡¶∏‡ßã‡¶∞‡ßç‡¶∏ ‡¶™‡ßç‡¶≤‡ßá‡¶≤‡¶ø‡¶∏‡ßç‡¶ü ‡¶•‡ßá‡¶ï‡ßá ‡¶®‡¶ø‡¶∞‡ßç‡¶¶‡¶ø‡¶∑‡ßç‡¶ü ‡¶ó‡ßç‡¶∞‡ßÅ‡¶™‡ßá‡¶∞ ‡¶∏‡¶¨ ‡¶ö‡ßç‡¶Ø‡¶æ‡¶®‡ßá‡¶≤ extract ‡¶ï‡¶∞‡ßá"""
            channels = []
            
            with open(source_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # ‡¶®‡¶ø‡¶∞‡ßç‡¶¶‡¶ø‡¶∑‡ßç‡¶ü ‡¶ó‡ßç‡¶∞‡ßÅ‡¶™‡ßá‡¶∞ ‡¶∏‡¶¨ ‡¶ö‡ßç‡¶Ø‡¶æ‡¶®‡ßá‡¶≤ ‡¶ñ‡ßÅ‡¶Å‡¶ú‡ßá ‡¶¨‡ßá‡¶∞ ‡¶ï‡¶∞‡¶æ
            pattern = r'(#EXTINF:-1[^\n]*group-title="[^"]*{}[^"]*"[^\n]*\n)(http[^\n]+)'.format(re.escape(group_title))
            
            matches = re.finditer(pattern, content, re.IGNORECASE)
            
            for match in matches:
                extinf_line = match.group(1).strip()
                url_line = match.group(2).strip()
                
                # tvg-logo extract ‡¶ï‡¶∞‡¶æ
                logo_match = re.search(r'tvg-logo="([^"]*)"', extinf_line)
                tvg_logo = logo_match.group(1) if logo_match else "https://i.postimg.cc/d1hHy4ss/11.png"
                
                # ‡¶ó‡ßç‡¶∞‡ßÅ‡¶™ ‡¶Ö‡¶®‡ßÅ‡¶Ø‡¶æ‡ßü‡ßÄ ‡¶ö‡ßç‡¶Ø‡¶æ‡¶®‡ßá‡¶≤ ‡¶®‡¶æ‡¶Æ ‡¶®‡¶ø‡¶∞‡ßç‡¶ß‡¶æ‡¶∞‡¶£
                channel_name = get_channel_name_strategy(group_title, extinf_line)
                
                channels.append({
                    'extinf_line': extinf_line,
                    'url_line': url_line,
                    'tvg_logo': tvg_logo,
                    'channel_name': channel_name,
                    'group_title': group_title
                })
            
            print(f"‚úÖ Found {len(channels)} channels for group '{group_title}'")
            return channels
        
        def force_groups_at_line(main_content, all_group_channels, target_line):
            """‡¶∏‡¶¨‡¶∏‡¶Æ‡¶Ø‡¶º ‡¶®‡¶ø‡¶∞‡ßç‡¶¶‡¶ø‡¶∑‡ßç‡¶ü ‡¶≤‡¶æ‡¶á‡¶®‡ßá ‡¶∏‡¶¨ ‡¶ó‡ßç‡¶∞‡ßÅ‡¶™‡ßá‡¶∞ ‡¶∏‡ßá‡¶ï‡¶∂‡¶® ‡¶∞‡¶æ‡¶ñ‡ßá"""
            timestamp = get_bangladesh_time()
            
            # ‡¶∏‡¶¨ ‡¶ó‡ßç‡¶∞‡ßÅ‡¶™‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø combined section ‡¶§‡ßà‡¶∞‡¶ø ‡¶ï‡¶∞‡¶æ
            new_combined_section = f"#AUTO-UPDATED - Multiple Groups - {timestamp}\n"
            
            total_channels = 0
            has_any_channels = False
            
            for group_title, channels in all_group_channels.items():
                if channels and len(channels) > 0:  # ‡¶∂‡ßÅ‡¶ß‡ßÅ channels ‡¶•‡¶æ‡¶ï‡¶≤‡ßá ‡¶è‡¶¨‡¶Ç empty ‡¶®‡¶æ ‡¶π‡¶≤‡ßá ‡¶Ø‡ßã‡¶ó ‡¶ï‡¶∞‡¶¨‡ßá
                    new_combined_section += f"# --- {group_title} Group ---\n"
                    
                    for channel in channels:
                        # ‡¶®‡¶§‡ßÅ‡¶® EXTINF ‡¶≤‡¶æ‡¶á‡¶® ‡¶§‡ßà‡¶∞‡¶ø ‡¶ï‡¶∞‡¶æ - ‡¶ó‡ßç‡¶∞‡ßÅ‡¶™ ‡¶Ö‡¶®‡ßÅ‡¶Ø‡¶æ‡ßü‡ßÄ ‡¶ö‡ßç‡¶Ø‡¶æ‡¶®‡ßá‡¶≤ ‡¶®‡¶æ‡¶Æ
                        new_extinf_line = f'#EXTINF:-1 tvg-logo="{channel["tvg_logo"]}" group-title="{group_title}", {channel["channel_name"]}\n'
                        new_combined_section += new_extinf_line
                        new_combined_section += channel["url_line"] + "\n"
                    
                    total_channels += len(channels)
                    has_any_channels = True
                    print(f"üì∫ Added {len(channels)} channels for {group_title}")
            
            # No channels found ‡¶≤‡¶æ‡¶á‡¶® ‡¶Ø‡ßã‡¶ó ‡¶ï‡¶∞‡¶æ ‡¶π‡¶¨‡ßá ‡¶®‡¶æ
            if not has_any_channels:
                print("‚ÑπÔ∏è No channels found for any active group - creating empty AUTO-UPDATED section")
            
            # ‡¶Æ‡ßá‡¶á‡¶® ‡¶ï‡¶®‡ßç‡¶ü‡ßá‡¶®‡ßç‡¶ü‡¶ï‡ßá ‡¶≤‡¶æ‡¶á‡¶®‡ßá ‡¶≠‡¶æ‡¶ó ‡¶ï‡¶∞‡¶æ
            lines = main_content.split('\n')
            
            # TARGET_LINE_NUMBER validation
            if target_line < 1:
                target_line = 1
            if target_line > len(lines):
                target_line = len(lines)
            
            print(f"üìç Target line: {target_line} (Total lines: {len(lines)})")
            
            # existing ANY AUTO-UPDATED section ‡¶ñ‡ßÅ‡¶Å‡¶ú‡ßá ‡¶¨‡ßá‡¶∞ ‡¶ï‡¶∞‡¶æ ‡¶è‡¶¨‡¶Ç ‡¶∏‡¶∞‡¶æ‡¶®‡ßã (‡¶™‡ßÅ‡¶∞‡¶æ‡¶®‡ßã ‡¶∏‡¶¨ versions)
            auto_updated_start = -1
            auto_updated_end = -1
            
            # existing section ‡¶è‡¶∞ ‡¶∂‡ßÅ‡¶∞‡ßÅ ‡¶è‡¶¨‡¶Ç ‡¶∂‡ßá‡¶∑ ‡¶ñ‡ßÅ‡¶Å‡¶ú‡¶æ - ANY AUTO-UPDATED section
            for i, line in enumerate(lines):
                if '#AUTO-UPDATED' in line and 'Multiple Groups' in line:
                    auto_updated_start = i
                    print(f"üîç Found existing AUTO-UPDATED section at line {i+1}")
                    # section ‡¶è‡¶∞ ‡¶∂‡ßá‡¶∑ ‡¶ñ‡ßÅ‡¶Å‡¶ú‡¶æ
                    for j in range(i + 1, len(lines)):
                        if not (lines[j].startswith('#EXTINF') or lines[j].startswith('http') or lines[j].startswith('# ---') or lines[j].strip() == ''):
                            auto_updated_end = j
                            break
                    if auto_updated_end == -1:
                        auto_updated_end = len(lines)
                    break
            
            if auto_updated_start != -1:
                print(f"üóëÔ∏è Removing existing AUTO-UPDATED section (lines {auto_updated_start+1}-{auto_updated_end})")
                # existing section ‡¶∏‡¶∞‡¶æ‡¶®‡ßã
                lines = lines[:auto_updated_start] + lines[auto_updated_end:]
            
            # ‡¶®‡¶§‡ßÅ‡¶® section ‡¶ü‡¶æ‡¶∞‡ßç‡¶ó‡ßá‡¶ü ‡¶≤‡¶æ‡¶á‡¶®‡ßá ‡¶Ø‡ßã‡¶ó ‡¶ï‡¶∞‡¶æ
            insert_position = target_line - 1  # 0-based index
            
            # ‡¶Ø‡¶¶‡¶ø insert position existing removal ‡¶è‡¶∞ ‡¶™‡¶∞ ‡¶™‡¶∞‡¶ø‡¶¨‡¶∞‡ßç‡¶§‡¶® ‡¶π‡¶Ø‡¶º‡ßá ‡¶•‡¶æ‡¶ï‡ßá, adjust ‡¶ï‡¶∞‡¶æ
            if auto_updated_start != -1 and auto_updated_start < insert_position:
                insert_position -= (auto_updated_end - auto_updated_start)
            
            if insert_position > len(lines):
                insert_position = len(lines)
            
            new_lines = lines[:insert_position] + new_combined_section.split('\n') + lines[insert_position:]
            updated_content = '\n'.join(new_lines)
            
            print(f"‚úÖ Multiple Groups section positioned at line {target_line}")
            
            return updated_content, total_channels
        
        # All Channel update ‡¶è‡¶∞ ‡¶™‡¶∞‡ßá‡¶∞ temporary ‡¶´‡¶æ‡¶á‡¶≤ ‡¶≤‡ßã‡¶° ‡¶ï‡¶∞‡ßÅ‡¶®
        with open('temp_after_all_channel.m3u', 'r', encoding='utf-8') as f:
            main_content = f.read()
        
        # Check if manual run or scheduled
        import os
        is_manual_run = os.environ.get('GITHUB_EVENT_NAME') == 'workflow_dispatch'
        
        # Filter out commented groups (lines starting with #)
        active_groups = [group for group in TARGET_GROUP_TITLES if not group.startswith('#')]
        
        if not active_groups:
            print("‚ùå ERROR: No active groups found! Please uncomment at least one group in TARGET_GROUP_TITLES")
            print("Current TARGET_GROUP_TITLES:", TARGET_GROUP_TITLES)
            exit(1)
        
        print(f"üéØ Active groups: {active_groups}")
        
        # ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶ü‡¶ø active ‡¶ó‡ßç‡¶∞‡ßÅ‡¶™ ‡¶ü‡¶æ‡¶á‡¶ü‡ßá‡¶≤‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶ö‡ßç‡¶Ø‡¶æ‡¶®‡ßá‡¶≤ extract ‡¶ï‡¶∞‡ßÅ‡¶®
        all_group_channels = {}
        total_found_channels = 0
        has_any_channels_found = False
        
        for group_title in active_groups:
            print(f"\nüîç Processing group: {group_title}")
            channels = extract_group_channels('fancode_source.m3u', group_title)
            # ‡¶∂‡ßÅ‡¶ß‡ßÅ channels ‡¶•‡¶æ‡¶ï‡¶≤‡ßá all_group_channels ‡¶è ‡¶Ø‡ßã‡¶ó ‡¶ï‡¶∞‡¶¨‡ßá
            if channels:
                all_group_channels[group_title] = channels
                total_found_channels += len(channels)
                has_any_channels_found = True
            else:
                print(f"‚ÑπÔ∏è No channels found for group '{group_title}', skipping...")
        
        # ‡¶Ø‡¶¶‡¶ø ‡¶ï‡ßã‡¶® ‡¶ó‡ßç‡¶∞‡ßÅ‡¶™‡ßá‡¶á ‡¶ö‡ßç‡¶Ø‡¶æ‡¶®‡ßá‡¶≤ ‡¶®‡¶æ ‡¶•‡¶æ‡¶ï‡ßá, ‡¶§‡¶æ‡¶π‡¶≤‡ßá ‡¶∂‡ßÅ‡¶ß‡ßÅ empty AUTO-UPDATED section ‡¶§‡ßà‡¶∞‡¶ø ‡¶ï‡¶∞‡¶¨‡ßá
        if not has_any_channels_found:
            print("‚ÑπÔ∏è No channels found for any active group, creating empty AUTO-UPDATED section...")
            # ‡¶∂‡ßÅ‡¶ß‡ßÅ timestamp ‡¶∏‡¶π AUTO-UPDATED ‡¶≤‡¶æ‡¶á‡¶® ‡¶Ø‡ßã‡¶ó ‡¶ï‡¶∞‡¶¨‡ßá
            all_group_channels = {}  # ‡¶ñ‡¶æ‡¶≤‡¶ø ‡¶∞‡¶æ‡¶ñ‡¶æ
        
        # ‡¶Æ‡ßá‡¶á‡¶® ‡¶™‡ßç‡¶≤‡ßá‡¶≤‡¶ø‡¶∏‡ßç‡¶ü ‡¶Ü‡¶™‡¶°‡ßá‡¶ü ‡¶ï‡¶∞‡ßÅ‡¶® - ‡¶∏‡¶¨‡¶∏‡¶Æ‡¶Ø‡¶º TARGET_LINE_NUMBER ‡¶è ‡¶∞‡¶æ‡¶ñ‡¶¨‡ßá
        updated_content, total_added_channels = force_groups_at_line(main_content, all_group_channels, TARGET_LINE_NUMBER)
        
        # ‡¶Ü‡¶™‡¶°‡ßá‡¶ü ‡¶ï‡¶∞‡¶æ ‡¶ï‡¶®‡ßç‡¶ü‡ßá‡¶®‡ßç‡¶ü ‡¶´‡¶æ‡¶á‡¶®‡¶æ‡¶≤ ‡¶´‡¶æ‡¶á‡¶≤‡ßá ‡¶∏‡ßá‡¶≠ ‡¶ï‡¶∞‡ßÅ‡¶®
        with open('sirometv_updated.m3u', 'w', encoding='utf-8') as f:
            f.write(updated_content)
        
        print(f"\nüéâ Live Fancode üîÑ Update Summary:")
        print(f"   Run type: {'Manual' if is_manual_run else 'Scheduled'}")
        print(f"   Target line: {TARGET_LINE_NUMBER}")
        print(f"   Total active groups: {len(active_groups)}")
        print(f"   Total channels found: {total_found_channels}")
        print(f"   Total channels added: {total_added_channels}")
        print(f"   Configuration:")
        print(f"     - TARGET_LINE_NUMBER = {TARGET_LINE_NUMBER}")
        print(f"     - Active groups = {active_groups}")
        
        # ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶ü‡¶ø ‡¶ó‡ßç‡¶∞‡ßÅ‡¶™‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶Ü‡¶≤‡¶æ‡¶¶‡¶æ summary
        print(f"\nüìä Group-wise Summary:")
        for group_title in active_groups:
            if group_title in all_group_channels:
                channels = all_group_channels[group_title]
                channel_count = len(channels)
                status = "‚úÖ" if channel_count > 0 else "‚ùå"
                
                if channel_count > 0:
                    first_channel_name = channels[0]['channel_name']
                    naming_strategy = ""
                    if group_title == "Live Event":
                        naming_strategy = "(all named 'üî¥Live Nowüî¥')"
                    elif group_title == "Sports":
                        naming_strategy = "(all named 'Sports Live')"
                    elif group_title == "Akash Go":
                        naming_strategy = "(original names preserved)"
                    else:
                        naming_strategy = "(original names)"
                    
                    print(f"   {status} {group_title}: {channel_count} channels {naming_strategy}")
                    if group_title == "Akash Go" and channel_count > 0:
                        print(f"      Sample: {first_channel_name}")
                else:
                    print(f"   {status} {group_title}: {channel_count} channels")
            else:
                print(f"   ‚ùå {group_title}: 0 channels (not found in source)")
        
        EOF
        
        echo "‚úÖ Live Fancode üîÑ update completed!"
        
    - name: Verify combined updates
      run: |
        echo "üîç Verifying combined playlist updates..."
        
        if [ ! -f "sirometv_updated.m3u" ] || [ ! -s "sirometv_updated.m3u" ]; then
          echo "‚ùå ERROR: Updated playlist is missing or empty!"
          exit 1
        fi
        
        # Compare with backup
        OLD_LINES=$(wc -l < main_playlist_backup.m3u)
        NEW_LINES=$(wc -l < sirometv_updated.m3u)
        DIFF=$((NEW_LINES - OLD_LINES))
        
        echo "üìä Line count comparison:"
        echo "   Original: $OLD_LINES lines"
        echo "   Updated: $NEW_LINES lines"
        echo "   Difference: $DIFF lines"
        
        # Check All Channel updates
        echo "üîç Checking All Channel üîÑ updates:"
        ALL_CHANNEL_UPDATES=$(grep -c "#AUTO-UPDATED -.*‚úÖ-" sirometv_updated.m3u || echo "0")
        ALL_CHANNEL_SKIPS=$(grep -c "#AUTO-UPDATED -.*‚õî SKIPPED ‚õî" sirometv_updated.m3u || echo "0")
        echo "   ‚úÖ All Channel updates: $ALL_CHANNEL_UPDATES channels"
        echo "   ‚õî All Channel skips: $ALL_CHANNEL_SKIPS channels"
        
        # Count total links for a sample channel
        JAMUNA_LINKS=$(grep -A 10 "Jamuna TV" sirometv_updated.m3u | grep -c "^http" || echo "0")
        echo "   üìä Sample - Jamuna TV has $JAMUNA_LINKS links"
        
        # Check order for Jamuna TV - verify Ayna links are on top
        echo "üîç Checking Jamuna TV link order (Ayna links should be on top):"
        JAMUNA_SECTION=$(grep -A 20 "Jamuna TV" sirometv_updated.m3u | head -15)
        JAMUNA_FIRST_FEW_LINKS=$(echo "$JAMUNA_SECTION" | grep "^http" | head -3)
        echo "   First few links for Jamuna TV:"
        echo "$JAMUNA_FIRST_FEW_LINKS" | while read line; do
          echo "     - $line"
        done
        
        # Check if Ayna links are present
        AYNA_LINKS_COUNT=$(echo "$JAMUNA_SECTION" | grep -c "aynaott\|app.com\|ayt.com" || echo "0")
        echo "   Ayna-specific links in Jamuna TV: $AYNA_LINKS_COUNT"
        
        if [ "$ALL_CHANNEL_UPDATES" -eq "0" ] && [ "$ALL_CHANNEL_SKIPS" -eq "0" ]; then
            echo "‚ö†Ô∏è Warning: No All Channel updates or skips found"
        else
            echo "‚úÖ All Channel updates verified"
        fi
        
        # Check Live Fancode updates
        echo "üîç Checking Live Fancode üîÑ updates:"
        MULTIPLE_GROUPS_SECTION=$(grep -c "#AUTO-UPDATED - üî¥Live Nowüî¥" sirometv_updated.m3u || echo "0")
        echo "   Multiple Groups section: $MULTIPLE_GROUPS_SECTION"
        
        if [ "$MULTIPLE_GROUPS_SECTION" -eq "0" ]; then
            echo "‚ö†Ô∏è Warning: No Multiple Groups section found"
        else
            # Check section position
            SECTION_LINE=$(grep -n "#AUTO-UPDATED - Multiple Groups" sirometv_updated.m3u | cut -d: -f1)
            echo "   üìç Multiple Groups section at line: $SECTION_LINE"
            
            # Check if at correct line
            if [ "$SECTION_LINE" -ne "25" ]; then
                echo "‚ö†Ô∏è Warning: Multiple Groups section not at line 25 (found at line $SECTION_LINE)"
            else
                echo "‚úÖ Multiple Groups section correctly positioned at line 25"
            fi
        fi
        
        # Check for Live Event group
        LIVE_EVENT_COUNT=$(grep -c 'group-title="Live Event"' sirometv_updated.m3u || echo "0")
        echo "   üì∫ Live Event channels: $LIVE_EVENT_COUNT"
        
        # Verify no "No channels found" lines
        if grep -q "No channels found" sirometv_updated.m3u; then
            echo "‚ùå ERROR: 'No channels found' line still exists!"
            exit 1
        else
            echo "‚úÖ 'No channels found' line is completely removed!"
        fi
        
        # Move final file to main playlist
        mv sirometv_updated.m3u sirometv.m3u
        
        echo "‚úÖ Combined verification completed!"
        
    - name: Commit and push changes
      run: |
        echo "üíæ Saving combined changes to repository..."
        
        git config user.name "github-actions[bot]"
        git config user.email "github-actions[bot]@users.noreply.github.com"
        git add sirometv.m3u
        
        if git diff --staged --quiet; then
          echo "‚úÖ No changes detected - playlist is up to date"
        else
          # ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ‡¶¶‡ßá‡¶∂‡ßá‡¶∞ ‡¶∏‡¶Æ‡ßü ‡¶®‡ßá‡¶ì‡ßü‡¶æ (BD Time format)
          BANGLADESH_TIME=$(TZ='Asia/Dhaka' date +'%Y-%m-%d %I:%M:%S%p BD Time')
          
          # Calculate channel counts
          ALL_CHANNEL_UPDATES=$(grep -c "#AUTO-UPDATED -.*‚úÖ-" sirometv.m3u || echo "0")
          ALL_CHANNEL_SKIPS=$(grep -c "#AUTO-UPDATED -.*‚õî SKIPPED ‚õî" sirometv.m3u || echo "0")
          LIVE_EVENT_COUNT=$(grep -c 'group-title="Live Event"' sirometv.m3u || echo "0")
          
          COMMIT_MESSAGE="üîÑ Combined Update: "
          
          if [ "${{ github.event_name }}" == "workflow_dispatch" ]; then
            COMMIT_MESSAGE+="Manual Run - "
          else
            COMMIT_MESSAGE+="Scheduled Run - "
          fi
          
          COMMIT_MESSAGE+="All Channel ($ALL_CHANNEL_UPDATES updates, $ALL_CHANNEL_SKIPS skips) + Live Event ($LIVE_EVENT_COUNT channels) - $BANGLADESH_TIME"
          
          git commit -m "$COMMIT_MESSAGE"
          git push
          
          echo "üéâ Successfully updated combined playlist!"
          echo "üìä Summary:"
          echo "   All Channel üîÑ: $ALL_CHANNEL_UPDATES channels updated"
          echo "   All Channel ‚õî: $ALL_CHANNEL_SKIPS channels skipped"
          echo "   Live Event: $LIVE_EVENT_COUNT channels"
          echo "   Time: $BANGLADESH_TIME"
        fi
        
    - name: Cleanup
      run: |
        echo "üßπ Cleaning up temporary files..."
        rm -f main_playlist.m3u main_playlist_backup.m3u
        rm -f source_playlist.m3u ayna_source.m3u fancode_source.m3u
        rm -f temp_after_all_channel.m3u
        echo "‚úÖ Cleanup completed!"
        
    - name: Success Notification
      if: success()
      run: |
        echo "üéä Combined workflow completed successfully!"
        echo "üìÖ Next update in 5 minutes"
        
    - name: Failure Notification
      if: failure()
      run: |
        echo "‚ùå Combined workflow failed!"
        echo "Please check the logs for errors."
        echo "Backup file may be available as main_playlist_backup.m3u"
