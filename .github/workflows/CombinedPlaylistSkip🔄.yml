name: Combined Playlist Skipper üîÑ

on:
  schedule:
    - cron: '*/5 * * * *'
  workflow_dispatch:

permissions:
  contents: write

jobs:
  update-playlists:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
        fetch-depth: 0
        
    - name: Download all playlists
      run: |
        echo "üì• Downloading all required playlists..."
        
        # ‡¶™‡ßç‡¶∞‡¶•‡¶Æ‡ßá ‡¶Æ‡ßá‡¶á‡¶® ‡¶™‡ßç‡¶≤‡ßá‡¶≤‡¶ø‡¶∏‡ßç‡¶ü ‡¶ñ‡¶æ‡¶≤‡¶ø ‡¶´‡¶æ‡¶á‡¶≤‡ßá ‡¶∞‡ßÇ‡¶™‡¶æ‡¶®‡ßç‡¶§‡¶∞
        echo "" > main_playlist.m3u
        
        # Source playlists
        curl -s -L -o source_playlist.m3u "https://raw.githubusercontent.com/sirometv/playlist/gh-pages/sirometv.m3u"
        curl -s -L -o ayna_source.m3u "https://raw.githubusercontent.com/sirometv/playlist/main/Ayna.m3u"
        curl -s -L -o fancode_source.m3u "https://raw.githubusercontent.com/abusaeeidx/Mrgify-BDIX-IPTV/main/playlist.m3u"
        
        # Verify downloads
        for file in source_playlist.m3u ayna_source.m3u fancode_source.m3u; do
          if [ ! -f "$file" ] || [ ! -s "$file" ]; then
            echo "‚ùå ERROR: $file download failed!"
            exit 1
          fi
          LINES=$(wc -l < "$file")
          echo "‚úÖ $file downloaded - $LINES lines"
        done
        
    - name: Copy from source to main playlist
      run: |
        echo "üìã Copying from source playlist to main playlist..."
        
        # ‡¶∏‡ßã‡¶∞‡ßç‡¶∏ ‡¶™‡ßç‡¶≤‡ßá‡¶≤‡¶ø‡¶∏‡ßç‡¶ü ‡¶•‡ßá‡¶ï‡ßá ‡¶Æ‡ßá‡¶á‡¶® ‡¶™‡ßç‡¶≤‡ßá‡¶≤‡¶ø‡¶∏‡ßç‡¶ü‡ßá ‡¶ï‡¶™‡¶ø ‡¶ï‡¶∞‡ßÅ‡¶®
        cp source_playlist.m3u main_playlist.m3u
        
        # Verify copy
        if [ ! -s "main_playlist.m3u" ]; then
          echo "‚ùå ERROR: main_playlist.m3u is empty after copy!"
          exit 1
        fi
        
        LINES=$(wc -l < "main_playlist.m3u")
        echo "‚úÖ Main playlist now has $LINES lines"
        
    - name: Backup original playlist
      run: |
        cp main_playlist.m3u main_playlist_backup.m3u
        echo "üì¶ Original playlist backed up"
        
    - name: Update All Channel üîÑ
      run: |
        echo "üîÑ Starting All Channel üîÑ update..."
        
        python3 - << 'EOF'
        import re
        from datetime import datetime
        import pytz
        import os
        
        # ‡¶ö‡ßç‡¶Ø‡¶æ‡¶®‡ßá‡¶≤ ‡¶Æ‡ßç‡¶Ø‡¶æ‡¶™‡¶ø‡¶Ç - ‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶™‡ßç‡¶∞‡¶•‡¶Æ ‡¶™‡ßç‡¶≤‡ßá‡¶≤‡¶ø‡¶∏‡ßç‡¶ü‡ßá‡¶∞ ‡¶®‡¶æ‡¶Æ : ‡¶∏‡ßá‡¶ï‡ßá‡¶®‡ßç‡¶° ‡¶™‡ßç‡¶≤‡ßá‡¶≤‡¶ø‡¶∏‡ßç‡¶ü‡ßá ‡¶ñ‡ßÅ‡¶Å‡¶ú‡¶¨‡ßá ‡¶è‡¶Æ‡¶® keywords
        CHANNEL_MAPPING = {
            "BTV National": ["BTV NATIONAL HD", "BTV World"],
            "BTV CTG": ["BTV CTG"],
            "Somoy TV": ["Somoy News TV", "Somoy TV"],
            "Jamuna TV": ["Jamuna TV","JAMUNA TV"],
            "Ekushey TV": ["Ekushey TV"],
            "NTV BD": ["NTV"],
            "NTV-Europe": ["NTV Europe"],
            "Channel 24": ["Channel 24"],
            "Deen TV": ["Deen TV"],
            "SATV": ["SA TV"],
            "GTV": ["Gazi TV"],
            "T Sports": ["T Sports HD", "A Sports", "PTV Sports"],
            "Channel 9": ["Channel 9"],
            "Channel I": ["Channel I"],
            "Bangla Vision": ["Bangla Vision"],
            "News 24": ["News 24 BD"], 
            "Boishakhi TV": ["Boishakhi TV"],
            "Bijoy TV": ["Bijoy TV"],
            "ATN Bangla": ["ATN Bangla"],
            "ATN-Bangla News": ["ATN News"],
            "DBC News": ["DBC News"],
            "Independent TV": ["Independent TV"],
            "Bangla TV": ["Bangla TV"],
            "Desh TV": ["Desh TV"],
            "RTV": ["RTV"],
            "My TV": ["My TV"],
            "Duronto": ["Duronto TV"],
            "Deepto TV": ["Deepto TV"],
            "Mohona TV": ["Mohona TV"],
            "Ananda TV": ["Ananda TV"],
            "Asian TV": ["Asian TV"],
            "Gaan Bangla": ["Gaan Bangla", "GAAN BANGLA", "gaan bangla", "Gaan", "GAAN"],
            "Channel 5 TV": ["Channel 5 TV"],
            "Music Bangla": ["Music Bangla"],
            "Ekattor TV": ["Ekattor TV"],
            "Nagorik TV": ["Nagorik TV"],
            "Ekhon TV": ["Ekhon TV"],
            "Peace TV Bangla": ["Peace TV Bangla HD"],
            "Islam Bangla": ["Islam Bangla"],
            "Iqra TV ": ["Iqra Bangla"],
            "Madani TV": ["Madani TV"],
            "News21 TV": ["News21 TV"],
            "Bangla 21": ["Bangla 21"],
            "Movie Bangla": ["Movie Bangla"],
            "Matri Bhumi": ["Matri Bhumi"],
            "Magic Bangla": ["Magic Bangla"],
            "Alpona TV": ["Alpona TV"],
            "Channel A1": ["Channel A1"],
            "Shadin Bangla": ["Shadin Bangla"],
            "Channel S UK": ["Channel S UK HD"],
            "Nandan TV": ["Nandan TV"],
            "Global TV": ["Global TV"],
            "Deshi TV": ["Deshi TV", "Deshi TV (720p)"],
            "Falguni TV": ["Falguni TV"],
            "Channel S BD": ["Channel S BD","Channel S HD"],
            "Rajdhani TV": ["Rajdhani TV"],
            "Rongeen TV": ["Rongeen TV"],
            "Sonic Bangla": ["Sonic Bangla"],
            "Discovery Kids": ["Discovery Kids"],
            "NAN TV": ["NAN TV"],
            "Star Jalsha": ["Star Jalsha HD", "Star Jalsha"],
            "Star-Jalsha Movies": ["Star Jalsha Movies HD"],
            "Zee Bangla": ["Zee Bangla International", "Zee Bangla"],
            "Zee-Bangla Cinema": ["Zee Bangla Cinema"],
            "Colors Bengali": ["colors bangla"],
            "Sangeet Bangla": ["Sangeet Bangla"],
            "Sony Aaat": ["Sony Aaat"],
            "Enter 10 Bangla": ["Enter 10 Bangla"],
            "Zee 24 Ghanta": ["Zee 24 Ghanta"],
        }
        
        def get_bangladesh_time():
            """‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ‡¶¶‡ßá‡¶∂‡ßá‡¶∞ ‡¶¨‡¶∞‡ßç‡¶§‡¶Æ‡¶æ‡¶® ‡¶∏‡¶Æ‡¶Ø‡¶º ‡¶∞‡¶ø‡¶ü‡¶æ‡¶∞‡ßç‡¶® ‡¶ï‡¶∞‡ßá"""
            bangladesh_tz = pytz.timezone('Asia/Dhaka')
            now = datetime.now(bangladesh_tz)
            return now.strftime("%Y-%m-%d %I:%M:%S%p BD Time")
        
        def find_channel_url(source_file, keywords):
            """‡¶∏‡ßã‡¶∞‡ßç‡¶∏ ‡¶™‡ßç‡¶≤‡ßá‡¶≤‡¶ø‡¶∏‡ßç‡¶ü ‡¶•‡ßá‡¶ï‡ßá ‡¶ö‡ßç‡¶Ø‡¶æ‡¶®‡ßá‡¶≤ URL ‡¶ñ‡ßÅ‡¶Å‡¶ú‡ßá ‡¶¨‡ßá‡¶∞ ‡¶ï‡¶∞‡ßá"""
            with open(source_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # ‡¶∏‡¶¨ keywords ‡¶è‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶ö‡ßá‡¶∑‡ßç‡¶ü‡¶æ ‡¶ï‡¶∞‡ßÅ‡¶®
            for keyword in keywords:
                pattern = r'#EXTINF:[^\n]*{}[^\n]*\n(http[^\n]+)'.format(re.escape(keyword))
                match = re.search(pattern, content, re.IGNORECASE)
                
                if match:
                    url = match.group(1).strip()
                    print(f"‚úÖ Found URL for keyword '{keyword}': {url}")
                    return url
            
            print(f"‚ùå No URL found for keywords: {keywords}")
            return None
        
        def get_current_channel_info(main_content, channel_name):
            """‡¶Æ‡ßá‡¶á‡¶® ‡¶™‡ßç‡¶≤‡ßá‡¶≤‡¶ø‡¶∏‡ßç‡¶ü ‡¶•‡ßá‡¶ï‡ßá ‡¶ö‡ßç‡¶Ø‡¶æ‡¶®‡ßá‡¶≤‡ßá‡¶∞ ‡¶¨‡¶∞‡ßç‡¶§‡¶Æ‡¶æ‡¶® URL ‡¶è‡¶¨‡¶Ç AUTO-UPDATED ‡¶≤‡¶æ‡¶á‡¶® ‡¶ñ‡ßÅ‡¶Å‡¶ú‡ßá ‡¶¨‡ßá‡¶∞ ‡¶ï‡¶∞‡ßá"""
            # Pattern: #EXTINF ‡¶≤‡¶æ‡¶á‡¶® ‡¶Ø‡ßá‡¶ñ‡¶æ‡¶®‡ßá channel_name ‡¶Ü‡¶õ‡ßá, ‡¶§‡¶æ‡¶∞‡¶™‡¶∞ URL ‡¶≤‡¶æ‡¶á‡¶®
            pattern = r'(#EXTINF:-1[^\n]*{}[^\n]*\n)(#AUTO-UPDATED[^\n]*\n)?(http[^\n]+)'.format(re.escape(channel_name))
            match = re.search(pattern, main_content, re.IGNORECASE)
            
            if match:
                extinf_line = match.group(1).strip()
                auto_updated_line = match.group(2).strip() if match.group(2) else None
                current_url = match.group(3).strip()
                print(f"üìå Found current info for {channel_name}:")
                print(f"   URL: {current_url}")
                print(f"   Has AUTO-UPDATED: {'Yes' if auto_updated_line else 'No'}")
                return {
                    'extinf_line': extinf_line,
                    'auto_updated_line': auto_updated_line,
                    'current_url': current_url
                }
            
            print(f"‚ö†Ô∏è No current info found for {channel_name}")
            return None
        
        def update_channel_url(main_content, channel_name, new_url, is_manual_run=False):
            """‡¶Æ‡ßá‡¶á‡¶® ‡¶™‡ßç‡¶≤‡ßá‡¶≤‡¶ø‡¶∏‡ßç‡¶ü‡ßá ‡¶®‡¶ø‡¶∞‡ßç‡¶¶‡¶ø‡¶∑‡ßç‡¶ü ‡¶ö‡ßç‡¶Ø‡¶æ‡¶®‡ßá‡¶≤‡ßá‡¶∞ URL ‡¶Ü‡¶™‡¶°‡ßá‡¶ü ‡¶ï‡¶∞‡ßá"""
            timestamp = get_bangladesh_time()
            
            # ‡¶™‡ßç‡¶∞‡¶•‡¶Æ‡ßá ‡¶¨‡¶∞‡ßç‡¶§‡¶Æ‡¶æ‡¶® ‡¶ö‡ßç‡¶Ø‡¶æ‡¶®‡ßá‡¶≤‡ßá‡¶∞ ‡¶§‡¶•‡ßç‡¶Ø ‡¶ñ‡ßÅ‡¶Å‡¶ú‡ßá ‡¶¨‡ßá‡¶∞ ‡¶ï‡¶∞‡ßÅ‡¶®
            channel_info = get_current_channel_info(main_content, channel_name)
            if not channel_info:
                print(f"‚ùå {channel_name} not found in main playlist")
                return main_content
            
            current_url = channel_info['current_url']
            auto_updated_line = channel_info['auto_updated_line']
            
            # ‡¶ö‡ßá‡¶ï ‡¶ï‡¶∞‡ßÅ‡¶® ‡¶Ø‡¶¶‡¶ø ‡¶¨‡¶∞‡ßç‡¶§‡¶Æ‡¶æ‡¶® URL ‡¶è‡¶¨‡¶Ç ‡¶®‡¶§‡ßÅ‡¶® URL ‡¶è‡¶ï‡¶á ‡¶π‡¶Ø‡¶º
            if current_url and new_url and current_url == new_url:
                # ‡¶è‡¶ï‡¶á URL, SKIPPED ‡¶Æ‡¶æ‡¶∞‡ßç‡¶ï ‡¶ï‡¶∞‡ßÅ‡¶®
                new_auto_updated_line = f"#AUTO-UPDATED - {channel_name} ‚õî SKIPPED ‚õî - {timestamp} üü° - üîÑ - üî¥\n"
                print(f"‚õî Same URL found for {channel_name}, marking as SKIPPED")
                is_skipped = True
                url_to_use = current_url  # ‡¶è‡¶ï‡¶á URL ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡ßÅ‡¶®
            else:
                # ‡¶≠‡¶ø‡¶®‡ßç‡¶® URL, ‡¶∏‡¶´‡¶≤ ‡¶Ü‡¶™‡¶°‡ßá‡¶ü ‡¶Æ‡¶æ‡¶∞‡ßç‡¶ï ‡¶ï‡¶∞‡ßÅ‡¶®
                new_auto_updated_line = f"#AUTO-UPDATED - {channel_name} ‚úÖ- {timestamp} üü° - üîÑ - üî¥\n"
                is_skipped = False
                url_to_use = new_url  # ‡¶®‡¶§‡ßÅ‡¶® URL ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡ßÅ‡¶®
            
            # ‡¶Æ‡ßá‡¶á‡¶® ‡¶ï‡¶®‡ßç‡¶ü‡ßá‡¶®‡ßç‡¶ü ‡¶Ü‡¶™‡¶°‡ßá‡¶ü ‡¶ï‡¶∞‡¶æ‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶™‡ßç‡¶Ø‡¶æ‡¶ü‡¶æ‡¶∞‡ßç‡¶® ‡¶§‡ßà‡¶∞‡¶ø ‡¶ï‡¶∞‡ßÅ‡¶®
            if auto_updated_line:
                # ‡¶Ø‡¶¶‡¶ø ‡¶Ü‡¶ó‡ßá ‡¶•‡ßá‡¶ï‡ßá AUTO-UPDATED ‡¶≤‡¶æ‡¶á‡¶® ‡¶•‡¶æ‡¶ï‡ßá
                pattern = r'({})({})({})'.format(
                    re.escape(channel_info['extinf_line']),
                    re.escape(auto_updated_line),
                    re.escape(current_url + '\n')
                )
                
                replacement = r'\1' + new_auto_updated_line + url_to_use + '\n'
            else:
                # ‡¶Ø‡¶¶‡¶ø AUTO-UPDATED ‡¶≤‡¶æ‡¶á‡¶® ‡¶®‡¶æ ‡¶•‡¶æ‡¶ï‡ßá
                pattern = r'({})({})'.format(
                    re.escape(channel_info['extinf_line']),
                    re.escape(current_url + '\n')
                )
                
                replacement = r'\1' + new_auto_updated_line + url_to_use + '\n'
            
            # ‡¶∞‡¶ø‡¶™‡ßç‡¶≤‡ßá‡¶∏‡¶Æ‡ßá‡¶®‡ßç‡¶ü ‡¶ï‡¶∞‡ßÅ‡¶®
            updated_content = re.sub(pattern, replacement, main_content, flags=re.IGNORECASE)
            
            action = "Skipped" if is_skipped else "Updated"
            print(f"‚úÖ {action} {channel_name}")
            
            return updated_content
        
        # ‡¶Æ‡ßá‡¶á‡¶® ‡¶™‡ßç‡¶≤‡ßá‡¶≤‡¶ø‡¶∏‡ßç‡¶ü ‡¶≤‡ßã‡¶° ‡¶ï‡¶∞‡ßÅ‡¶®
        with open('main_playlist.m3u', 'r', encoding='utf-8') as f:
            main_content = f.read()
        
        # Check if manual run or scheduled
        is_manual_run = os.environ.get('GITHUB_EVENT_NAME') == 'workflow_dispatch'
        
        updated_content = main_content
        update_count = 0
        skip_count = 0
        
        # ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶ü‡¶ø ‡¶ö‡ßç‡¶Ø‡¶æ‡¶®‡ßá‡¶≤‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶Ü‡¶™‡¶°‡ßá‡¶ü ‡¶ï‡¶∞‡ßÅ‡¶®
        for main_channel, search_keywords in CHANNEL_MAPPING.items():
            print(f"\nüîç Processing: {main_channel}")
            print(f"   Run type: {'Manual' if is_manual_run else 'Scheduled'}")
            
            new_url = find_channel_url('ayna_source.m3u', search_keywords)
            
            if new_url:
                # ‡¶¨‡¶∞‡ßç‡¶§‡¶Æ‡¶æ‡¶® URL ‡¶ñ‡ßÅ‡¶Å‡¶ú‡ßá ‡¶¨‡ßá‡¶∞ ‡¶ï‡¶∞‡ßÅ‡¶®
                channel_info = get_current_channel_info(updated_content, main_channel)
                if channel_info and channel_info['current_url'] and channel_info['current_url'] == new_url:
                    print(f"‚õî Skipping {main_channel} - same URL in main and source")
                    skip_count += 1
                else:
                    update_count += 1
                updated_content = update_channel_url(updated_content, main_channel, new_url, is_manual_run)
            else:
                print(f"‚ö†Ô∏è Skipping {main_channel} - no URL found")
        
        # ‡¶Ü‡¶™‡¶°‡ßá‡¶ü ‡¶ï‡¶∞‡¶æ ‡¶ï‡¶®‡ßç‡¶ü‡ßá‡¶®‡ßç‡¶ü temporary ‡¶´‡¶æ‡¶á‡¶≤‡ßá ‡¶∏‡ßá‡¶≠ ‡¶ï‡¶∞‡ßÅ‡¶®
        with open('temp_after_all_channel.m3u', 'w', encoding='utf-8') as f:
            f.write(updated_content)
        
        print(f"\nüéâ All Channel üîÑ Update Summary:")
        print(f"   Run type: {'Manual' if is_manual_run else 'Scheduled'}")
        print(f"   Total channels processed: {len(CHANNEL_MAPPING)}")
        print(f"   Successfully updated: {update_count}")
        print(f"   Skipped (same URL): {skip_count}")
        print(f"   Failed: {len(CHANNEL_MAPPING) - update_count - skip_count}")
        
        EOF
        
        echo "‚úÖ All Channel üîÑ update completed!"
        
    - name: Update Live Fancode üîÑ
      run: |
        echo "üîÑ Starting Live Fancode üîÑ update..."
        
        python3 - << 'EOF'
        import re
        from datetime import datetime
        import pytz
        
        # ‚öôÔ∏è CONFIGURATION
        TARGET_LINE_NUMBER = 25  # ‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶á‡¶ö‡ßç‡¶õ‡¶æ‡¶Æ‡¶§ ‡¶≤‡¶æ‡¶á‡¶® ‡¶®‡¶Æ‡ßç‡¶¨‡¶∞ ‡¶™‡¶∞‡¶ø‡¶¨‡¶∞‡ßç‡¶§‡¶® ‡¶ï‡¶∞‡ßÅ‡¶®
        
        # ‡¶ó‡ßç‡¶∞‡ßÅ‡¶™ ‡¶ü‡¶æ‡¶á‡¶ü‡ßá‡¶≤‡ßá‡¶∞ ‡¶≤‡¶ø‡¶∏‡ßç‡¶ü
        TARGET_GROUP_TITLES = [
            "Live Event",
            # "Cricket",    # uncomment ‡¶ï‡¶∞‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡ßá‡¶® ‡¶Ø‡¶¶‡¶ø ‡¶™‡ßç‡¶∞‡ßü‡ßã‡¶ú‡¶® ‡¶π‡ßü
            # "Akash Go",    # uncomment ‡¶ï‡¶∞‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡ßá‡¶® ‡¶Ø‡¶¶‡¶ø ‡¶™‡ßç‡¶∞‡ßü‡ßã‡¶ú‡¶® ‡¶π‡ßü
            # "Football",    # uncomment ‡¶ï‡¶∞‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡ßá‡¶® ‡¶Ø‡¶¶‡¶ø ‡¶™‡ßç‡¶∞‡ßü‡ßã‡¶ú‡¶® ‡¶π‡ßü
            # "Sports",      # uncomment ‡¶ï‡¶∞‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡ßá‡¶® ‡¶Ø‡¶¶‡¶ø ‡¶™‡ßç‡¶∞‡ßü‡ßã‡¶ú‡¶® ‡¶π‡ßü
            # "Movies",      # uncomment ‡¶ï‡¶∞‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡ßá‡¶® ‡¶Ø‡¶¶‡¶ø ‡¶™‡ßç‡¶∞‡ßü‡ßã‡¶ú‡¶® ‡¶π‡ßü
        ]
        
        def get_bangladesh_time():
            """‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ‡¶¶‡ßá‡¶∂‡ßá‡¶∞ ‡¶¨‡¶∞‡ßç‡¶§‡¶Æ‡¶æ‡¶® ‡¶∏‡¶Æ‡¶Ø‡¶º ‡¶∞‡¶ø‡¶ü‡¶æ‡¶∞‡ßç‡¶® ‡¶ï‡¶∞‡ßá"""
            bangladesh_tz = pytz.timezone('Asia/Dhaka')
            now = datetime.now(bangladesh_tz)
            return now.strftime("%Y-%m-%d %I:%M:%S%p BD Time")
        
        def get_channel_name_strategy(group_title, extinf_line):
            """‡¶ó‡ßç‡¶∞‡ßÅ‡¶™ ‡¶Ö‡¶®‡ßÅ‡¶Ø‡¶æ‡ßü‡ßÄ ‡¶ö‡ßç‡¶Ø‡¶æ‡¶®‡ßá‡¶≤ ‡¶®‡¶æ‡¶Æ‡ßá‡¶∞ strategy ‡¶®‡¶ø‡¶∞‡ßç‡¶ß‡¶æ‡¶∞‡¶£ ‡¶ï‡¶∞‡ßá"""
            # ‡¶ö‡ßç‡¶Ø‡¶æ‡¶®‡ßá‡¶≤ ‡¶®‡¶æ‡¶Æ extract ‡¶ï‡¶∞‡¶æ
            channel_name_match = re.search(r',([^,\n]+)$', extinf_line)
            original_name = channel_name_match.group(1).strip() if channel_name_match else ""
            
            if group_title == "Live Event":
                return "Fancode"  # Live Event ‡¶ó‡ßç‡¶∞‡ßÅ‡¶™‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶°‡¶ø‡¶´‡¶≤‡ßç‡¶ü ‡¶®‡¶æ‡¶Æ
            elif group_title == "Sports":
                return "Sports Live"  # Sports ‡¶ó‡ßç‡¶∞‡ßÅ‡¶™‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶°‡¶ø‡¶´‡¶≤‡ßç‡¶ü ‡¶®‡¶æ‡¶Æ
            elif group_title == "Akash Go":
                return original_name  # Akash Go ‡¶ó‡ßç‡¶∞‡ßÅ‡¶™‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶Ü‡¶∏‡¶≤ ‡¶®‡¶æ‡¶Æ ‡¶∞‡¶æ‡¶ñ‡¶¨‡ßá
            else:
                return original_name  # ‡¶Ö‡¶®‡ßç‡¶Ø‡¶æ‡¶®‡ßç‡¶Ø ‡¶ó‡ßç‡¶∞‡ßÅ‡¶™‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶Ü‡¶∏‡¶≤ ‡¶®‡¶æ‡¶Æ
        
        def extract_group_channels(source_file, group_title):
            """‡¶∏‡ßã‡¶∞‡ßç‡¶∏ ‡¶™‡ßç‡¶≤‡ßá‡¶≤‡¶ø‡¶∏‡ßç‡¶ü ‡¶•‡ßá‡¶ï‡ßá ‡¶®‡¶ø‡¶∞‡ßç‡¶¶‡¶ø‡¶∑‡ßç‡¶ü ‡¶ó‡ßç‡¶∞‡ßÅ‡¶™‡ßá‡¶∞ ‡¶∏‡¶¨ ‡¶ö‡ßç‡¶Ø‡¶æ‡¶®‡ßá‡¶≤ extract ‡¶ï‡¶∞‡ßá"""
            channels = []
            
            with open(source_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # ‡¶®‡¶ø‡¶∞‡ßç‡¶¶‡¶ø‡¶∑‡ßç‡¶ü ‡¶ó‡ßç‡¶∞‡ßÅ‡¶™‡ßá‡¶∞ ‡¶∏‡¶¨ ‡¶ö‡ßç‡¶Ø‡¶æ‡¶®‡ßá‡¶≤ ‡¶ñ‡ßÅ‡¶Å‡¶ú‡ßá ‡¶¨‡ßá‡¶∞ ‡¶ï‡¶∞‡¶æ
            pattern = r'(#EXTINF:-1[^\n]*group-title="[^"]*{}[^"]*"[^\n]*\n)(http[^\n]+)'.format(re.escape(group_title))
            
            matches = re.finditer(pattern, content, re.IGNORECASE)
            
            for match in matches:
                extinf_line = match.group(1).strip()
                url_line = match.group(2).strip()
                
                # tvg-logo extract ‡¶ï‡¶∞‡¶æ
                logo_match = re.search(r'tvg-logo="([^"]*)"', extinf_line)
                tvg_logo = logo_match.group(1) if logo_match else "https://i.postimg.cc/d1hHy4ss/11.png"
                
                # ‡¶ó‡ßç‡¶∞‡ßÅ‡¶™ ‡¶Ö‡¶®‡ßÅ‡¶Ø‡¶æ‡ßü‡ßÄ ‡¶ö‡ßç‡¶Ø‡¶æ‡¶®‡ßá‡¶≤ ‡¶®‡¶æ‡¶Æ ‡¶®‡¶ø‡¶∞‡ßç‡¶ß‡¶æ‡¶∞‡¶£
                channel_name = get_channel_name_strategy(group_title, extinf_line)
                
                channels.append({
                    'extinf_line': extinf_line,
                    'url_line': url_line,
                    'tvg_logo': tvg_logo,
                    'channel_name': channel_name,
                    'group_title': group_title
                })
            
            print(f"‚úÖ Found {len(channels)} channels for group '{group_title}'")
            return channels
        
        def force_groups_at_line(main_content, all_group_channels, target_line):
            """‡¶∏‡¶¨‡¶∏‡¶Æ‡¶Ø‡¶º ‡¶®‡¶ø‡¶∞‡ßç‡¶¶‡¶ø‡¶∑‡ßç‡¶ü ‡¶≤‡¶æ‡¶á‡¶®‡ßá ‡¶∏‡¶¨ ‡¶ó‡ßç‡¶∞‡ßÅ‡¶™‡ßá‡¶∞ ‡¶∏‡ßá‡¶ï‡¶∂‡¶® ‡¶∞‡¶æ‡¶ñ‡ßá"""
            timestamp = get_bangladesh_time()
            
            # ‡¶∏‡¶¨ ‡¶ó‡ßç‡¶∞‡ßÅ‡¶™‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø combined section ‡¶§‡ßà‡¶∞‡¶ø ‡¶ï‡¶∞‡¶æ
            new_combined_section = f"#AUTO-UPDATED - Multiple Groups - {timestamp}\n"
            
            total_channels = 0
            has_any_channels = False
            
            for group_title, channels in all_group_channels.items():
                if channels and len(channels) > 0:  # ‡¶∂‡ßÅ‡¶ß‡ßÅ channels ‡¶•‡¶æ‡¶ï‡¶≤‡ßá ‡¶è‡¶¨‡¶Ç empty ‡¶®‡¶æ ‡¶π‡¶≤‡ßá ‡¶Ø‡ßã‡¶ó ‡¶ï‡¶∞‡¶¨‡ßá
                    new_combined_section += f"# --- {group_title} Group ---\n"
                    
                    for channel in channels:
                        # ‡¶®‡¶§‡ßÅ‡¶® EXTINF ‡¶≤‡¶æ‡¶á‡¶® ‡¶§‡ßà‡¶∞‡¶ø ‡¶ï‡¶∞‡¶æ - ‡¶ó‡ßç‡¶∞‡ßÅ‡¶™ ‡¶Ö‡¶®‡ßÅ‡¶Ø‡¶æ‡ßü‡ßÄ ‡¶ö‡ßç‡¶Ø‡¶æ‡¶®‡ßá‡¶≤ ‡¶®‡¶æ‡¶Æ
                        new_extinf_line = f'#EXTINF:-1 tvg-logo="{channel["tvg_logo"]}" group-title="{group_title}", {channel["channel_name"]}\n'
                        new_combined_section += new_extinf_line
                        new_combined_section += channel["url_line"] + "\n"
                    
                    total_channels += len(channels)
                    has_any_channels = True
                    print(f"üì∫ Added {len(channels)} channels for {group_title}")
            
            # No channels found ‡¶≤‡¶æ‡¶á‡¶® ‡¶Ø‡ßã‡¶ó ‡¶ï‡¶∞‡¶æ ‡¶π‡¶¨‡ßá ‡¶®‡¶æ
            if not has_any_channels:
                print("‚ÑπÔ∏è No channels found for any active group - creating empty AUTO-UPDATED section")
            
            # ‡¶Æ‡ßá‡¶á‡¶® ‡¶ï‡¶®‡ßç‡¶ü‡ßá‡¶®‡ßç‡¶ü‡¶ï‡ßá ‡¶≤‡¶æ‡¶á‡¶®‡ßá ‡¶≠‡¶æ‡¶ó ‡¶ï‡¶∞‡¶æ
            lines = main_content.split('\n')
            
            # TARGET_LINE_NUMBER validation
            if target_line < 1:
                target_line = 1
            if target_line > len(lines):
                target_line = len(lines)
            
            print(f"üìç Target line: {target_line} (Total lines: {len(lines)})")
            
            # existing ANY AUTO-UPDATED section ‡¶ñ‡ßÅ‡¶Å‡¶ú‡ßá ‡¶¨‡ßá‡¶∞ ‡¶ï‡¶∞‡¶æ ‡¶è‡¶¨‡¶Ç ‡¶∏‡¶∞‡¶æ‡¶®‡ßã (‡¶™‡ßÅ‡¶∞‡¶æ‡¶®‡ßã ‡¶∏‡¶¨ versions)
            auto_updated_start = -1
            auto_updated_end = -1
            
            # existing section ‡¶è‡¶∞ ‡¶∂‡ßÅ‡¶∞‡ßÅ ‡¶è‡¶¨‡¶Ç ‡¶∂‡ßá‡¶∑ ‡¶ñ‡ßÅ‡¶Å‡¶ú‡¶æ - ANY AUTO-UPDATED section
            for i, line in enumerate(lines):
                if '#AUTO-UPDATED' in line and 'Multiple Groups' in line:
                    auto_updated_start = i
                    print(f"üîç Found existing AUTO-UPDATED section at line {i+1}")
                    # section ‡¶è‡¶∞ ‡¶∂‡ßá‡¶∑ ‡¶ñ‡ßÅ‡¶Å‡¶ú‡¶æ
                    for j in range(i + 1, len(lines)):
                        if not (lines[j].startswith('#EXTINF') or lines[j].startswith('http') or lines[j].startswith('# ---') or lines[j].strip() == ''):
                            auto_updated_end = j
                            break
                    if auto_updated_end == -1:
                        auto_updated_end = len(lines)
                    break
            
            if auto_updated_start != -1:
                print(f"üóëÔ∏è Removing existing AUTO-UPDATED section (lines {auto_updated_start+1}-{auto_updated_end})")
                # existing section ‡¶∏‡¶∞‡¶æ‡¶®‡ßã
                lines = lines[:auto_updated_start] + lines[auto_updated_end:]
            
            # ‡¶®‡¶§‡ßÅ‡¶® section ‡¶ü‡¶æ‡¶∞‡ßç‡¶ó‡ßá‡¶ü ‡¶≤‡¶æ‡¶á‡¶®‡ßá ‡¶Ø‡ßã‡¶ó ‡¶ï‡¶∞‡¶æ
            insert_position = target_line - 1  # 0-based index
            
            # ‡¶Ø‡¶¶‡¶ø insert position existing removal ‡¶è‡¶∞ ‡¶™‡¶∞ ‡¶™‡¶∞‡¶ø‡¶¨‡¶∞‡ßç‡¶§‡¶® ‡¶π‡¶Ø‡¶º‡ßá ‡¶•‡¶æ‡¶ï‡ßá, adjust ‡¶ï‡¶∞‡¶æ
            if auto_updated_start != -1 and auto_updated_start < insert_position:
                insert_position -= (auto_updated_end - auto_updated_start)
            
            if insert_position > len(lines):
                insert_position = len(lines)
            
            new_lines = lines[:insert_position] + new_combined_section.split('\n') + lines[insert_position:]
            updated_content = '\n'.join(new_lines)
            
            print(f"‚úÖ Multiple Groups section positioned at line {target_line}")
            
            return updated_content, total_channels
        
        # All Channel update ‡¶è‡¶∞ ‡¶™‡¶∞‡ßá‡¶∞ temporary ‡¶´‡¶æ‡¶á‡¶≤ ‡¶≤‡ßã‡¶° ‡¶ï‡¶∞‡ßÅ‡¶®
        with open('temp_after_all_channel.m3u', 'r', encoding='utf-8') as f:
            main_content = f.read()
        
        # Check if manual run or scheduled
        import os
        is_manual_run = os.environ.get('GITHUB_EVENT_NAME') == 'workflow_dispatch'
        
        # Filter out commented groups (lines starting with #)
        active_groups = [group for group in TARGET_GROUP_TITLES if not group.startswith('#')]
        
        if not active_groups:
            print("‚ùå ERROR: No active groups found! Please uncomment at least one group in TARGET_GROUP_TITLES")
            print("Current TARGET_GROUP_TITLES:", TARGET_GROUP_TITLES)
            exit(1)
        
        print(f"üéØ Active groups: {active_groups}")
        
        # ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶ü‡¶ø active ‡¶ó‡ßç‡¶∞‡ßÅ‡¶™ ‡¶ü‡¶æ‡¶á‡¶ü‡ßá‡¶≤‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶ö‡ßç‡¶Ø‡¶æ‡¶®‡ßá‡¶≤ extract ‡¶ï‡¶∞‡ßÅ‡¶®
        all_group_channels = {}
        total_found_channels = 0
        has_any_channels_found = False
        
        for group_title in active_groups:
            print(f"\nüîç Processing group: {group_title}")
            channels = extract_group_channels('fancode_source.m3u', group_title)
            # ‡¶∂‡ßÅ‡¶ß‡ßÅ channels ‡¶•‡¶æ‡¶ï‡¶≤‡ßá all_group_channels ‡¶è ‡¶Ø‡ßã‡¶ó ‡¶ï‡¶∞‡¶¨‡ßá
            if channels:
                all_group_channels[group_title] = channels
                total_found_channels += len(channels)
                has_any_channels_found = True
            else:
                print(f"‚ÑπÔ∏è No channels found for group '{group_title}', skipping...")
        
        # ‡¶Ø‡¶¶‡¶ø ‡¶ï‡ßã‡¶® ‡¶ó‡ßç‡¶∞‡ßÅ‡¶™‡ßá‡¶á ‡¶ö‡ßç‡¶Ø‡¶æ‡¶®‡ßá‡¶≤ ‡¶®‡¶æ ‡¶•‡¶æ‡¶ï‡ßá, ‡¶§‡¶æ‡¶π‡¶≤‡ßá ‡¶∂‡ßÅ‡¶ß‡ßÅ empty AUTO-UPDATED section ‡¶§‡ßà‡¶∞‡¶ø ‡¶ï‡¶∞‡¶¨‡ßá
        if not has_any_channels_found:
            print("‚ÑπÔ∏è No channels found for any active group, creating empty AUTO-UPDATED section...")
            # ‡¶∂‡ßÅ‡¶ß‡ßÅ timestamp ‡¶∏‡¶π AUTO-UPDATED ‡¶≤‡¶æ‡¶á‡¶® ‡¶Ø‡ßã‡¶ó ‡¶ï‡¶∞‡¶¨‡ßá
            all_group_channels = {}  # ‡¶ñ‡¶æ‡¶≤‡¶ø ‡¶∞‡¶æ‡¶ñ‡¶æ
        
        # ‡¶Æ‡ßá‡¶á‡¶® ‡¶™‡ßç‡¶≤‡ßá‡¶≤‡¶ø‡¶∏‡ßç‡¶ü ‡¶Ü‡¶™‡¶°‡ßá‡¶ü ‡¶ï‡¶∞‡ßÅ‡¶® - ‡¶∏‡¶¨‡¶∏‡¶Æ‡¶Ø‡¶º TARGET_LINE_NUMBER ‡¶è ‡¶∞‡¶æ‡¶ñ‡¶¨‡ßá
        updated_content, total_added_channels = force_groups_at_line(main_content, all_group_channels, TARGET_LINE_NUMBER)
        
        # ‡¶Ü‡¶™‡¶°‡ßá‡¶ü ‡¶ï‡¶∞‡¶æ ‡¶ï‡¶®‡ßç‡¶ü‡ßá‡¶®‡ßç‡¶ü ‡¶´‡¶æ‡¶á‡¶®‡¶æ‡¶≤ ‡¶´‡¶æ‡¶á‡¶≤‡ßá ‡¶∏‡ßá‡¶≠ ‡¶ï‡¶∞‡ßÅ‡¶®
        with open('sirometv_updated.m3u', 'w', encoding='utf-8') as f:
            f.write(updated_content)
        
        print(f"\nüéâ Live Fancode üîÑ Update Summary:")
        print(f"   Run type: {'Manual' if is_manual_run else 'Scheduled'}")
        print(f"   Target line: {TARGET_LINE_NUMBER}")
        print(f"   Total active groups: {len(active_groups)}")
        print(f"   Total channels found: {total_found_channels}")
        print(f"   Total channels added: {total_added_channels}")
        print(f"   Configuration:")
        print(f"     - TARGET_LINE_NUMBER = {TARGET_LINE_NUMBER}")
        print(f"     - Active groups = {active_groups}")
        
        # ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶ü‡¶ø ‡¶ó‡ßç‡¶∞‡ßÅ‡¶™‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶Ü‡¶≤‡¶æ‡¶¶‡¶æ summary
        print(f"\nüìä Group-wise Summary:")
        for group_title in active_groups:
            if group_title in all_group_channels:
                channels = all_group_channels[group_title]
                channel_count = len(channels)
                status = "‚úÖ" if channel_count > 0 else "‚ùå"
                
                if channel_count > 0:
                    first_channel_name = channels[0]['channel_name']
                    naming_strategy = ""
                    if group_title == "Live Event":
                        naming_strategy = "(all named 'Fancode')"
                    elif group_title == "Sports":
                        naming_strategy = "(all named 'Sports Live')"
                    elif group_title == "Akash Go":
                        naming_strategy = "(original names preserved)"
                    else:
                        naming_strategy = "(original names)"
                    
                    print(f"   {status} {group_title}: {channel_count} channels {naming_strategy}")
                    if group_title == "Akash Go" and channel_count > 0:
                        print(f"      Sample: {first_channel_name}")
                else:
                    print(f"   {status} {group_title}: {channel_count} channels")
            else:
                print(f"   ‚ùå {group_title}: 0 channels (not found in source)")
        
        EOF
        
        echo "‚úÖ Live Fancode üîÑ update completed!"
        
    - name: Verify combined updates
      run: |
        echo "üîç Verifying combined playlist updates..."
        
        if [ ! -f "sirometv_updated.m3u" ] || [ ! -s "sirometv_updated.m3u" ]; then
          echo "‚ùå ERROR: Updated playlist is missing or empty!"
          exit 1
        fi
        
        # Compare with backup
        OLD_LINES=$(wc -l < main_playlist_backup.m3u)
        NEW_LINES=$(wc -l < sirometv_updated.m3u)
        DIFF=$((NEW_LINES - OLD_LINES))
        
        echo "üìä Line count comparison:"
        echo "   Original: $OLD_LINES lines"
        echo "   Updated: $NEW_LINES lines"
        echo "   Difference: $DIFF lines"
        
        # Check All Channel updates
        echo "üîç Checking All Channel üîÑ updates:"
        ALL_CHANNEL_UPDATES=$(grep -c "#AUTO-UPDATED -.*‚úÖ-" sirometv_updated.m3u || echo "0")
        ALL_CHANNEL_SKIPPED=$(grep -c "#AUTO-UPDATED -.*‚õî SKIPPED ‚õî" sirometv_updated.m3u || echo "0")
        echo "   ‚úÖ All Channel updates: $ALL_CHANNEL_UPDATES channels"
        echo "   ‚õî All Channel skipped: $ALL_CHANNEL_SKIPPED channels"
        
        # Check for duplicate URLs
        echo "üîç Checking for duplicate URLs..."
        DUP_COUNT=$(grep -A1 "#AUTO-UPDATED -.*‚õî SKIPPED ‚õî" sirometv_updated.m3u | grep "^http" | wc -l)
        echo "   Duplicate URL lines after SKIPPED: $DUP_COUNT"
        
        if [ "$ALL_CHANNEL_UPDATES" -eq "0" ] && [ "$ALL_CHANNEL_SKIPPED" -eq "0" ]; then
            echo "‚ö†Ô∏è Warning: No All Channel updates found"
        else
            echo "‚úÖ All Channel updates verified"
        fi
        
        # Check Live Fancode updates
        echo "üîç Checking Live Fancode üîÑ updates:"
        MULTIPLE_GROUPS_SECTION=$(grep -c "#AUTO-UPDATED - Multiple Groups" sirometv_updated.m3u || echo "0")
        echo "   Multiple Groups section: $MULTIPLE_GROUPS_SECTION"
        
        if [ "$MULTIPLE_GROUPS_SECTION" -eq "0" ]; then
            echo "‚ö†Ô∏è Warning: No Multiple Groups section found"
        else
            # Check section position
            SECTION_LINE=$(grep -n "#AUTO-UPDATED - Multiple Groups" sirometv_updated.m3u | cut -d: -f1)
            echo "   üìç Multiple Groups section at line: $SECTION_LINE"
            
            # Check if at correct line
            if [ "$SECTION_LINE" -ne "25" ]; then
                echo "‚ö†Ô∏è Warning: Multiple Groups section not at line 25 (found at line $SECTION_LINE)"
            else
                echo "‚úÖ Multiple Groups section correctly positioned at line 25"
            fi
        fi
        
        # Check for Live Event group
        LIVE_EVENT_COUNT=$(grep -c 'group-title="Live Event"' sirometv_updated.m3u || echo "0")
        echo "   üì∫ Live Event channels: $LIVE_EVENT_COUNT"
        
        # Verify no "No channels found" lines
        if grep -q "No channels found" sirometv_updated.m3u; then
            echo "‚ùå ERROR: 'No channels found' line still exists!"
            exit 1
        else
            echo "‚úÖ 'No channels found' line is completely removed!"
        fi
        
        # Move final file to main playlist
        mv sirometv_updated.m3u sirometv.m3u
        
        echo "‚úÖ Combined verification completed!"
        
    - name: Commit and push changes
      run: |
        echo "üíæ Saving combined changes to repository..."
        
        git config user.name "github-actions[bot]"
        git config user.email "github-actions[bot]@users.noreply.github.com"
        git add sirometv.m3u
        
        if git diff --staged --quiet; then
          echo "‚úÖ No changes detected - playlist is up to date"
        else
          # ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ‡¶¶‡ßá‡¶∂‡ßá‡¶∞ ‡¶∏‡¶Æ‡ßü ‡¶®‡ßá‡¶ì‡ßü‡¶æ (BD Time format)
          BANGLADESH_TIME=$(TZ='Asia/Dhaka' date +'%Y-%m-%d %I:%M:%S%p BD Time')
          
          # Calculate channel counts
          ALL_CHANNEL_UPDATES=$(grep -c "#AUTO-UPDATED -.*‚úÖ-" sirometv.m3u || echo "0")
          ALL_CHANNEL_SKIPPED=$(grep -c "#AUTO-UPDATED -.*‚õî SKIPPED ‚õî" sirometv.m3u || echo "0")
          LIVE_EVENT_COUNT=$(grep -c 'group-title="Live Event"' sirometv.m3u || echo "0")
          
          COMMIT_MESSAGE="üîÑ Combined Update: "
          
          if [ "${{ github.event_name }}" == "workflow_dispatch" ]; then
            COMMIT_MESSAGE+="Manual Run - "
          else
            COMMIT_MESSAGE+="Scheduled Run - "
          fi
          
          COMMIT_MESSAGE+="All Channel ($ALL_CHANNEL_UPDATES updates, $ALL_CHANNEL_SKIPPED skipped) + Live Event ($LIVE_EVENT_COUNT channels) - $BANGLADESH_TIME"
          
          git commit -m "$COMMIT_MESSAGE"
          git push
          
          echo "üéâ Successfully updated combined playlist!"
          echo "üìä Summary:"
          echo "   All Channel üîÑ: $ALL_CHANNEL_UPDATES channels updated"
          echo "   All Channel ‚õî: $ALL_CHANNEL_SKIPPED channels skipped"
          echo "   Live Event: $LIVE_EVENT_COUNT channels"
          echo "   Time: $BANGLADESH_TIME"
        fi
        
    - name: Cleanup
      run: |
        echo "üßπ Cleaning up temporary files..."
        rm -f main_playlist.m3u main_playlist_backup.m3u
        rm -f source_playlist.m3u ayna_source.m3u fancode_source.m3u
        rm -f temp_after_all_channel.m3u
        echo "‚úÖ Cleanup completed!"
        
    - name: Success Notification
      if: success()
      run: |
        echo "üéä Combined workflow completed successfully!"
        echo "üìÖ Next update in 5 minutes"
        
    - name: Failure Notification
      if: failure()
      run: |
        echo "‚ùå Combined workflow failed!"
        echo "Please check the logs for errors."
        echo "Backup file may be available as main_playlist_backup.m3u"
